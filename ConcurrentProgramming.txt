
并发:
	同时拥有两个或者多个线程,如果程序在单核处理器上运行,多个线程交替地换入或者换出内存,这些线程是同时"存在"的,每个线程都处于执行过程中的某个状态,如果运行多核处理器上,此时,程序中每个线程都将分配到一个处理核上,因此,可以同时运行.

CPU多级缓存:
	*为什么需要CPU缓存呢?
	因为CPU的频率太快了,快到主存跟不上,这样在处理器时钟周期内,CPU常常需要等待主存,浪费资源.所以cache的出现,是为了缓解CPU和内存之间速度的不匹配问题(结构:CPU-->cache-->memory)	
	*保证缓存的一致性(MESI协议)
		参考博客: https://blog.csdn.net/muxiqingyang/article/details/6615199
	*乱序执行优化
	处理器为提高运算速度而做出的违背代码原有顺序的优化(重排序).单核的环境下处理结果与预期相同,但多核情况下,多个核来执行指令,每个核都可能被乱序,使得结果偏离预期.
	*Java内存模型(Java Memory Model --JMM)
		`它规定了一个线程如何和何时可以看到其他线程修改过的共享变量的值，以及在必须时如何同步地访问共享变量
		`堆Heap:运行时数据区，有垃圾回收，堆的优势可以动态分配内存大小，生存期也不必事先告诉编译器，因为他是在运行时动态分配内存。缺点是由于运行时动态分配内存，所以存取速度慢一些。
		`栈Stack:优势存取速度快，速度仅次于计算机的寄存器。栈的数据是可以共享的，但是缺点是存在栈中数据的大小与生存期必须是确定的。主要存放基本类型变量，对象据点。要求调用栈和本地变量存放在线程栈上。
		`静态类型变量跟随类的定义存放在堆上。存放在堆上的对象可以被所持有对这个对象引用的线程访问。
		`如果两个线程同时调用了同一个对象的同一个方法，他们都会访问这个对象的成员变量。但是这两个线程都拥有的是该对象的成员变量（局部变量）的私有拷贝。—[线程封闭中的堆栈封闭]
	*计算机硬件架构:
		`CPU Registers(寄存器):是CPU内存的基础，CPU在寄存器上执行操作的速度远大于在主存上执行的速度。这是因为CPU访问寄存器速度远大于主存。
		`CPU Cache Memory(高速缓存):由于计算机的存储设备与处理器的运算速度之间有着几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高级缓存，来作为内存与处理器之间的缓冲。将运算时所使用到的数据复制到缓存中,让运算能快速的进行。当运算结束后，再从缓存同步回内存之中，这样处理器就无需等待缓慢的内存读写了。
		`RAM-Main Memory(主存/内存):当一个CPU需要读取主存的时候，他会将主存中的部分读取到CPU缓存中，甚至他可能将缓存中的部分内容读到他的内部寄存器里面，然后在寄存器中执行操作。当`CPU需要将结果回写到主存的时候，他会将内部寄存器中的值刷新到缓存中，然后在某个时间点从缓存中刷回主存。
	*JMM与硬件架构的关系
		`Java内存模型抽象结构：每个线程都有一个私有的本地内存，本地内存他是java内存模型的一个抽象的概念。它并不是真实存在的，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器的优化。本地内存中它存储了该线程以读或写共享变量拷贝的一个副本。
		`从更低的层次来说，主内存就是硬件的内存，是为了获取更高的运行速度，虚拟机及硬件系统可能会让工作内存优先存储于寄存器和高速缓存中，java内存模型中的线程的工作内存是CPU的寄存器和高速缓存的一个抽象的描述。而JVM的静态内存存储模型它只是对内存的一种物理划分而已。它只局限在内存，而且只局限在JVM的内存。
	*JMM中线程与主内存中同步的八种操作
		1.lock（锁定）：作用于主内存的变量，把一个变量标识变为一条线程独占状态
		2.unlock（解锁）：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定
		3.read（读取）：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用
		4.load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中
		5.use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎
		6.assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接受到的值赋值给工作内存的变量
		7.store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作
		8.write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中
	同步规则:
		``如果要把一个变量从主内存中赋值到工作内存，就需要按顺序得执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序得执行store和write操作，但java内存模型只要求上述操作必须按顺序执行，没有保证必须是连续执行
		``不允许read和load、store和write操作之一单独出现
		``不允许一个线程丢弃他的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中
		``不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步到主内存中
		``一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了load和assign操作
		``一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以同时被一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会解锁，lock和unlock必须成对出现
		``如果一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎中使用这个变量前需要重新执行load或assign操作初始化变量的值
		``如果一个变量事先没有被lock操作锁定，则不允许他执行unlock操作，也不允许去unlock一个被其他线程锁定的变量
		``对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）

	并发的优势与风险:
	  优势:
		速度：同时处理多个请求，响应更快；复杂的操作可以分成多个进程同时进行。
		设计：程序设计在某些情况下更简单，也可以有更多选择
		资源利用：CPU能够在等待IO的时候做一些其他的事情
	  风险:
	  	安全性：多个线程共享数据时可能会产生于期望不相符的结果
		活跃性：某个操作无法继续进行下去时，就会发生活跃性问题。比如死锁、饥饿问题
		性能：线程过多时会使得CPU频繁切换，调度时间增多；同步机制；消耗过多内存。

	并发模拟工具:
		PostMan
		Apache Bench(AB):
			ab -n 1000 -c 50 http://localhost:8080/test	 请求1000次,最多允许同时50次访问(并发数为50)
		JMeter
	并发模拟代码:
		Semaphore , CountDownLatch

	原子性:

		AtomicXXX: CAS(compareAndSwap), Unsafe.compareAndSwapInt
		底层实现:
		//var1,传过来的count对象(AtomicInteger)
		//var2,该对象工作内存中的值
		//var4,要增加的值
		public final int getAndAddInt(Object var1, long var2, int var4) {
		//获取底层的该对象的值,主内存中的值
	        int var5;
	        do {
	            var5 = this.getIntVolatile(var1, var2);
	            //不断获取底层的值,直到和当前对象(工作内存中的)值相等(var2=var5).CAS,最终的目的是返回对象最新的值
	        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));
	        return var5;
	    }	

	    这里的compareAndSwapInt（var1, var2, var5, var5 + var4）换成 compareAndSwapInt（obj, offset, expect, update）能清楚一些，如果obj内的value和expect相等，就证明没有其他线程改变过这个变量，那么就更新它(主内存)为update,返回的值是var5给工作内存,然后工作内存又+1。

		CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。


		AtomicLong,LongAdder:(面试)
		AtomicLong:死循环方式,如果并发高竞争非常激烈，那么失败量就会很高，性能会受到影响
		LongAdder:jvm对long，double这些64位的变量拆成两个32位的操作,在高并发的场景，通过热点分区来提高并行度,缺点：在统计的时候如果有并发更新，可能会导致结果有些误差,要求数据精确的话不要使用

		compareAndSet:更多用到AtomicBoolean中,保证我们要控制的这段代码只被执行一次.

		AtomicReference:用法同AtomicInteger一样，但是可以放各种对象:AtomicReference<Integer> count = new AtomicReference<>(0);
		AtomicIntegerFieldUpdater:原子性的去更新某一个类的实例的指定的某一个字段.newUpdater()方法的第一个参数是某类的class文件,第二个参数是指定的字段名,注意:该字段必须是volatile修饰,并且不能是static修饰.

		AtomicStampReference:CAS的ABA问题
		ABA问题：在CAS操作的时候，其他线程将变量的值A改成了B由改成了A，本线程使用期望值A与当前变量进行比较的时候，发现A变量没有变，于是CAS就将A值进行了交换操作，这个时候实际上A值已经被其他线程改变过，这与设计思想是不符合的
		解决思路：每次变量更新的时候，把变量的版本号加一，这样只要变量被某一个线程修改过，该变量版本号就会发生递增操作，从而解决了ABA变化	

		AtomicLongArray可以指定更新一个数组指定索引位置的值compareAndSet(int i, long expect, long update)

		AtomicBoolean(平时用的比较多),在并发情况下可以让一段代码只被执行一次.
		AtomicBoolean isHappened =  new AtomicBoolean(false);
		if(isHappened.compareAndSet(false,ture)){
		//在高并发情况下if里面的代码只会被执行一次
			...
		}

	    native:
	    使用native关键字说明这个方法是原生函数，也就是这个方法是用C/C++语言实现的，并且被编译成了DLL，由java去调用。 这些函数的实现体在DLL中，JDK的源代码中并不包含，你应该是看不到的。对于不同的平台它们也是不同的。这也是java的底层机制，实际上java就是在不同的平台上调用不同的native方法实现对操作系统的访问的。

	    独占锁：是一种悲观锁，synchronized就是一种独占锁，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。

		乐观锁：每次不加锁，假设没有冲突去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁用到的机制就是CAS，Compare and Swap。CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

	原子性-锁-synchronize
	   synchronized：依赖JVM （主要依赖JVM实现锁，因此在这个关键字作用对象的作用范围内，都是同一时刻只能有一个线程进行操作的）
	   Lock：依赖特殊的CPU指令，代码实现，ReentrantLock

	   synchronize
	   修饰代码块:作用范围:大括号括起来的代码,作用于调用的对象.
	   修饰方法:作用范围:整个方法,作用于调用的对象.
	   修饰类:
	   synchronized (SyncronizedExample2.class){
	   ...
	   }
	   作用范围:括号括起来的部分,作用于该类的所有对象
	   修饰静态方法:作用范围:整个静态方法,作用于该类的所有对象

	   作用于调用的对象:多个线程同时执行同一个对象的example01.test()时,是一个先执行完再执行下一个.多个线程同时执行该类的两个对象example01.test(),example02.test(),结果是两个方法交替执行.
	   作用于调用的类:这个类的不同对象多线程执行方法,都是先执行完一个再执行下一个.
	原子性-对比
		synchronize:不可中断锁,适合竞争不激烈,可读性好
		lock:可中断锁,多样化同步,竞争激烈时能维持常态.
		Atomic:竞争激烈时能维持常态,比Lock性能好,但只能同步一个值

		“synchronized不能被继承”: synchronized并不属于方法定义的一部分，不能被继承。子类继承父类,子类覆写了该方法，如果在覆写时不明确写上synchronized，那这个方法就不是synchronized。换句话说，虽然继承了，但是没把synchronized继承下来.

		system.out.println在底层实现时本身会加上synchronized，会影响并发场景下的性能，也让本来的多线程并发变得多了很多阻塞，很多地方甚至变成单线程。因此，强烈建议别使用他

	线程安全性-可见性
		JVM对于可见性，提供了synchronized和volatile
		JMM关于synchronized的两条规定：
		线程解锁前，必须把共享变量的最新值刷新到主内存
		线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（注意：加锁与解锁是同一把锁）

		Volatile:通过加入内存屏障和禁止重排序优化来实现
		对volatile 变量写操作时，会在写操作后加入一条store屏障指令，将本地内存中的共享变量值刷新到主内存
		对volatile变量读操作时，会在读操作前加入一条load屏障指令，从主内存中读取共享变量
		volatitle的屏障操作都是CPU级别的,但不能保证原子性.其实它比较适合做状态标记量（不会涉及到多线程同时读写的操作）,而且要保证两点： 
		（1）对变量的写操作不依赖于当前值 
		（2）该变量没有包含在具有其他变量的不变的式子中 :
		程序的初始化标识:
		volatile boolean inited = false;
		//线程一：
		context = loadContext();
		inited = true;

		//线程二：
		while（!inited）{
		    sleep();
		}
		doSomethingWithConfig(context);

	线程安全性-有序性
		Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 
		java提供了 volatile、synchronized、Lock可以用来保证有序性 
        另外，java内存模型具备一些先天的有序性，即不需要任何手段就能得到保证的有序性。通常被我们成为happens-before原则（先行发生原则）。如果两个线程的执行顺序无法从happens-before原则推导出来，那么就不能保证它们的有序性，虚拟机就可以对它们进行重排序:

        程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作
		锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作
		volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作（重要）
		传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C
		线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作
		线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
		线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
		对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始


	安全发布对象-发布与逸出
		发布对象:使一个对象能够被当前范围之外的代码所使用。在我们的日常开发中，我们经常要发布一些对象，比如通过类的非私有方法返回对象的引用，或者通过公有静态变量发布对象。
	    对象逸出:一种错误的发布。当一个对象还没有构造完成时，就使它被其他线程所见。
	    不安全发布对象的两种代码演示:

	    如何安全发布对象？共有四种方法
	    1、在静态初始化函数中初始化一个对象引用
	    2、将对象的引用保存到volatile类型域或者AtomicReference对象中
	    3、将对象的引用保存到某个正确构造对象的final类型域中
	    4、将对象的引用保存到一个由锁保护的域中
	    我们用各种单例模式来演示其中的几种方法:懒汉式,饿汉式

	    静态块：用static申明，JVM加载类时执行，仅执行一次 
		构造块：类中直接用{}定义，每一次创建对象时执行 
		执行顺序优先级：静态块>main()>构造块>构造方法 
		静态块和静态属性优先执行，谁在前就先执行谁 

		单例: spring管理的bean通常都使用的单例，单例没有专属的使用场景，只要一个类实例化后可以一直使用，就可以设计成单例，减少频繁创建对象的开销

	不可变对象
		有一种对象只要它发布了就是安全的，它就是不可变对象。

		final关键字:
			修饰类：类不能被集成。
			  基础类型的包装类都是final类型的类。final类中的成员变量可以根据需要设置为final，但是要注意的是，final类中的所有成员方法都会被隐式的指定为final方法
			修饰方法：
			  (1)被继承后不能修改该方法
			  (2)效率：在早期的java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不见效果。一个private方法会被隐式的指定为final方法
			修饰变量：
			  基本数据类型变量，在初始化之后，它的值就不能被修改了。如果是引用类型变量，在它初始化之后便不能再指向另外的对象。(注意:被final修饰的引用类型变量，虽然不能重新指向，但是可以修改)

		创建不可变对象:
			1.Java的Collection类的unmodifiable相关方法,包含:unmodifiableList,unmodifiableMap,unmodifiableSet...
			   使用时: map = Collections.unmodifiableMap(map);

			   unmodifiable相关类的实现原理:
			   	 Collections.unmodifiableMap在执行时,将参数中的map对象进行了转换转换为Collection类中的内部类UnmodifiableMap对象。而UnmodifiableMap对map的更新方法（比如put、remove等）进行了重写，调用时均抛出UnsupportedOperationException异常，这样就做到了map对象的不可变。

			2.使用Guava的Immutable相关类,包含:ImmutableSet,ImmutableList,ImmutableMap...
				1)使用时: Immutablelist<Integer> list = ImmutableList.of(1,2,3);
					list.add(4);  这一句在书写完就会被IDE提示该add方法为过时方法，实际为不可用方法,运行时仍然会抛出UnsupportedOperationException异常.
				Immutable相关类实现原理:跟Java的unmodifiable相关类相似的实现方法.
				2)ImmutableSet除了使用of的方法进行初始化,还可以使用copyof方法,将Collection,iterator类型作为参数.
					private final static ImmutableSet set = ImmutableSet.copyOf(list);
					private final static ImmutableSet set = ImmutableSet.copyOf(list.iterator());
				3)ImmutableMap有特殊的builder写法：
					private final static ImmutableMap<Integer, Integer> map = ImmutableMap.of(1, 2, 3, 4);  //奇数位是key,偶数位是value
 					private final static ImmutableMap<Integer, Integer> map2 = ImmutableMap.<Integer, Integer>builder()
            		.put(1, 2).put(3, 4).put(5, 6).build();			//ImmutableMap的builder写法.

         问: ImmutableXXX修改的集合必须配上final才可以实现不可变对象，否则可以修改其对象引用，是这样吗?
         答: 是的，我们在使用一个不可变对象的实例时，其实很关键一点就是添加final修饰，否则我们很多接口来声明的类实例，在实际使用中被改了引用是一件很尴尬的事情。JDK里许多方法也要求传入接口参数必须是final修饰的变量，保证在方法处理过程中不会修改引用。否则一个参数传到一个方法将很不安全，因为你根本不知道这个方法会对传入的参数做怎样的处理，这也是一个比较好的实践，可以使用final时尽量使用。

    线程封闭:
        它其实就是把对象封装到一个线程里，只有一个线程能看到这个对象，那么这个对象就算不是线程安全的，也不会出现任何线程安全方面的问题。
        比如:
            JDBC的connection连接对象本身不是线程安全的,但是应用连接池,线程从连接池中取connection对象,在线程返回connection之前,连接池不会讲其分配给其他线程,等于将connection封闭到一个线程里面.这样虽然connection对象本身不是线程安全,但是同时连接池的线程封闭也能做到线程安全.
        (1)Ad-hoc 线程封闭：
        (2)堆栈封闭:
            堆栈封闭其实就是方法中定义局部变量。不存在并发问题。多个线程访问一个方法的时候，方法中的局部变量都会被拷贝一份到线程的栈中（Java内存模型），所以局部变量是不会被多个线程所共享的。
        (3)ThreadLocal 线程封闭: 特别好的线程封闭方法
            每个线程都会维护一个map,map的key是每个线程的名称而map的value就是我们要封闭的对象.多个线程互不干扰.

        ``创建一个包含ThreadLocal对象的类ThreadLocalCache，并提供基础的添加、删除、获取操作
        ``创建一个Filter,在Filter中对ThreadLocal做添加操作
        ``创建拦截器interceptor,重写preHandle()(它是进入url之前拦截处理)和afterCompletion()(它是执行完url之后拦截处理)方法,在afterCompletion方法中ThreadLocalCache.remove()释放,避免内存泄漏.
        ``在springboot的启动类Application中@Bean注册filter与interceptor.(也可以写一个配置类来@Bean注册)
        ``写一个Controller来模拟请求.
          先进filter,后进interceptor

        问:为什么要使用过滤器add和拦截器remove,用其中的一个就可以实现把
        答:首先如果项目里只有一个filter和一个interceptor，或者只有其中一种时，用其中一个就可以实现，这是没问题的。
           接下来，说一下这样做的目的。这样做，主要是考虑在项目中有多个filter和一个interceptor时，比如项目里同时有登录校验的filter、权限校验的filter，然后有一个interceptor做一些通用的记录（比如接口耗时）。这时，在登录校验的filter里把登录校验的信息写入threadLocal，然后需要在接口该执行的都执行完再从threadlocal中移除登录信息。在多个filter时，直接使用一个就很可能出现后面的filter还要使用，但是还没使用时就已经移除的情况。这时放到interceptor里保证最后阶段移除就明显更不容易出错了。

    常用的线程不安全的类:
    		(1)StringBuilder与StringBuffer
    			StringBuilder是线程不安全的，而StringBuffer是线程安全的。分析源码：StringBuffer的方法使用了synchronized关键字修饰。
    			StringBuilder效率高,可以在方法里做局部变量时使用,线程封闭.
    		(2)simpleDateFormat与jodatime插件
    			simpleDateFormat是线程不安全的,可以在new对象的时候将其放在方法里面,因为局部变量线程封闭,这样就是线程安全的.
    			jodatime插件可保证线程安全性.
    			Joda 类具有不可变性，因此它们的实例无法被修改。（不可变类的一个优点就是它们是线程安全的）
    			private static DateTimeFormatter dateTimeFormatter = DateTimeFormat.forPattern("yyyyMMdd");
    			private static void update(int i) {
    			    log.info("{}, {}", i, DateTime.parse("20180208", dateTimeFormatter).toDate());
    			}
    		(3)ArrayList,HashSet,HashMap等Collection类
    			线程不安全的原因,以arrayList为例,每次进行插入操作的时候,都会做扩容处理,会导致线程不安全.因为添加一个元素时会分两步来完成:
    				1.增大数组的size值
    				2.在数组Item[size]的位置存放此元素
    			由于这两步不是原子性的,所以多线程时会出现线程安全问题.
    		(4)先检查再执行: if(condition(a)){handle(a)};
    		   判断语句和执行语句无法保证原子性,所以线程不安全

    		问: 以下业务代码:
    		 for (Long houseId: houseIds) {
    		    //线程处理
    		    executorService.execute(() -> {
    		        //一些查询操作
    		        xxxService.select();
    		        //一些更新缓存的操作
    		        xxxRedis.update();
    		        if(如果不需要保存){
    				    //停止线程
    			        Thread.currentThread().interrup();
    		        }
    		        //一些添加操作
    		        xxxService.batchInsert();
    		    }
    		 }
    		 程序却会不断抛出InterruptedException,线程不是在wait, join, sleep时候被interrupt才会抛出这个异常吗?
    		答: 实际中很少有直接调用interrupt的，你如果想结束线程，直接return就可以了啊，你目前使用的是线程池，你很难知道其他线程是什么状态，完全交给线程池调度就可以了。

    		问: StringBuilder快，StringBuffer安全，那String这个类，顿时就有点尴尬了，那我们一般为什么不就用这两个类，干嘛还用String？（尽管我们知道，很多场景下，我们一般都是习惯性定义字符串为String）
    		这三者的应用场景有什么区别，什么情况下，我该用哪个类，尤其String类。
    		答: 字符串拼接的时候，用SringBuilder和StringBuffer性能更好，因为String是不能改变的，例如我们声明了一个String s = "abc";当我们改为String s = s+"de";的时候，其实是重新声明了一个String s，就是String s="abc"+"de";而不是直接在之前的String上面操作，所以会有性能上面的问题。而StringBuilder和StringBuffer调用append方法是直接在上面进行修改操作的，性能比String好。然后其余的问题就是StringBuilder是线程不安全的，而StringBuffer是线程安全的，在不同的场景进行选择了。 补充一点，如果String 后面是多个【常量】字符串拼接，其实和SringBuilder、StringBuffer也差不多，这时候编译器在编译阶段会做特殊的优化


    	同步容器:
    		(1)ArrayList的线程安全类: Vector和Stack
    		   Vector相当于加了synchronized的arrayList;
    		   Stack(栈)它继承了Vector,也是使用synchronized修饰了.
    		  但是同步容器在某些情况下是线程不安全的:
    		  比如并发执行删除与获取的操作.有可能上面刚删除完,下面就获取,就会报数组越界异常.因为synchronize只锁了方法,要想两个方法之间保证原子性就需要加上Lock或者synchronized来同步.
    		(2)HashMap的线程安全类: HashTable , 使用了synchronized修饰
            (3)Collections类中的相关同步方法:
                Collections.synchronizedList(List<T>);
                Collections.synchronizeMap(Map<K,T>);
                Collections.synchronizeSet(Set<T>);
                ...等等
             使用: private static List<Integer> list = Collections.synchronizedList(Lists.newArrayList());

             另外:使用foreach\iterator遍历集合的时候不能进行增删操作,会报错ConcurrentModificationException,使用for循环是ok的.
             解决办法:1.在循环里将循坏的对象标记,然后出循环时处理
                     2.在并发环境在可以通过加锁,或者使用并发容器来解决

        并发容器J.U.C:
            OOM - Out of Memory，内存溢出
            J.U.C是Java.util.concurrency缩写
            上面我们介绍了ArrayList、HashMap、HashSet对应的同步容器保证其线程安全，这节我们介绍一下其对应的并发容器。
            (1) ArrayList -> CopyOnWriteArrayList
                CopyOnWriteArrayList写操作时复制，当有新元素添加到集合中时，从原有的数组中拷贝一份出来，然后在新的数组上作写操作，将原来的数组指向新的数组。整个数组的add操作都是在锁的保护下进行的，防止并发时复制多份副本。读操作是在原数组中进行，不需要加锁
                ``缺点：
                1.写操作时复制消耗内存，如果元素比较多时候，容易导致young gc 和full gc。
                2.不能用于实时读的场景.由于复制和add操作等需要时间，故读取时可能读到旧值。
                能做到最终一致性，但无法满足实时性的要求，更适合读多写少的场景。
                ``优点:
                如果无法知道数组有多大，或者add,set操作有多少，慎用此类,在大量的复制副本的过程中很容易出错。
                设计思想：
                1.读写分离
                2.最终一致性
                3.使用时另外开辟空间，防止并发冲突
            (2) HashSet -> CopyOnWriteArraySet
                它是线程安全的，底层实现使用的是CopyOnWriteArrayList，因此它也适用于大小很小的set集合，只读操作远大于可变操作。因为他需要copy整个数组，所以包括add、remove、set它的开销相对于大一些。
            (3) TreeSet -> ConcurrentSkipListSet
                ``TreeSet: 它可以给Set集合中的元素进行指定方式(1自身具备比较性 2自定义比较器)的排序。
                ``同其他set集合，是基于map集合的（基于ConcurrentSkipListMap),在多线程环境下，里面的contains、add、remove操作都是线程安全的。
                ``多个线程可以安全的并发的执行插入、移除、和访问操作。但是对于批量操作addAll、removeAll、retainAll和containsAll并不能保证以原子方式执行，原因是addAll、removeAll、retainAll底层调用的还是contains、add、remove方法，只能保证每一次的执行是原子性的，代表在单一执行操纵时不会被打断，但是不能保证每一次批量操作都不会被打断。在使用批量操作时，还是需要手动加上同步操作的。
                ``不允许使用null元素的，它无法可靠的将参数及返回值与不存在的元素区分开来。
            (4) HashMap -> ConcurrentHashMap
                ``ConcurrentHashMap不允许空值,对读操作做了大量的优化,因此这个类在高并发环境下有特别好的表现,面试中经常问.
                ``ConcurrentHashMap作为Concurrent一族，其有着高效地并发操作，相比Hashtable的笨重，ConcurrentHashMap则更胜一筹了。
                ``在1.8版本以前，ConcurrentHashMap采用分段锁的概念，使锁更加细化，但是1.8已经改变了这种思路，而是利用CAS+Synchronized来保证并发更新的安全，当然底层采用数组+链表+红黑树的存储结构。
            (5) TreeMap -> ConcurrentSkipListMap
                ``底层实现采用SkipList跳表
                ``曾经有人用ConcurrentHashMap与ConcurrentSkipListMap做性能测试，在4个线程1.6W的数据条件下，前者的数据存取速度是后者的4倍左右。但是后者有几个前者不能比拟的优点：
                    1、Key是有序的
                    2、支持更高的并发，存储时间与线程数无关,也就是线程数越高越有优势

        安全共享对象策略:
            1.线程封闭: 一个被线程封闭的对象,由线程独占,并且只能被占有它的线程修改. 比如局部变量
            2.共享只读: 一个共享只读的对象, 可以被多个线程并发访问,但是任何线程都不能修改它. 比如不可变对象
            3.线程安全对象: 一个线程安全的对象或者容器,在内部通过同步机制来保障线程安全,其它线程无需额外的同步就可以通过公共接口随意访问它 , 比如并发容器(J.U.C)
            4.被守护对象: 被守护对象只能通过获取特定的锁来访问. 比如synchronize.lock加锁.

            问: 我看《Java并发编程实战》，里面介绍ReentrantReadWriteLock,读锁和写锁，里面说读锁类似于Semaphore而不是锁，只是维护当前活跃的读线程的数量，我知道读锁是共享锁而写锁是排它锁，那我的理解是共享锁不是一种真正的锁，那他又有什么意义呢？
            答: 你好，他存在的意义可以参考ReentrantLock，ReentrantLock实现了标准的互斥操作，也就是一次只能有一个线程持有锁，显然这个特点在一定程度上面减低了吞吐量。
            实际应用场景中我们会经常遇到这样的情况：某些资源需要并发访问，并且大部分时间是用来进行读操作的，写操作比较少，而锁是有一定的开销的，当并发比较大的时候，锁的开销就非常可观了。所以如果可能的话就尽量少用锁，如果非要用锁的话就尝试看能否能实现读写分离，将其改造为读写锁。
            ReentrantReadWriteLock主要就是为了解决这种场景，尽可能的减少排他锁的使用，同时也能保证足够的线程安全。
            问: 既然读操作很多，加排他锁的开销又大，那我直接对读操作不加任何锁不是更好吗，为啥还需要读锁
            答: 还记得课程开始部分讲线程安全时的例子不，不加锁时其他线程做了修改后，你当前的线程可能读取不到最新值，导致操作出现线程安全问题

            问: 老师，您好！volitile 修饰一个map 当map很大的时候会不会导致OOM？
            答: 你好，volatile本质上不会额外消耗内存，只是强制代码读取主存里最新的值。如果因为map过大导致oom，那本质上是map的问题，而不是因为有volatile修饰。
            问: 老师，主存是什么？我一直对这个词很模糊，是JVM里的堆，栈？
            答: 主存是公共空间，基本可以类比为虚拟机模型中的堆,对象创建好了都是在主存里，所有线程都可以访问。 工作内存是线程的私有内存，只有本线程可以访问，如果线程要操作主存中的某个对象，必须从主存中拷贝到工作内存，在对工作内存中的副本进行操作，操作后再写入主存，而不能对主存的对象直接操作。 volatile主要是在某些场合需要强制读取主存里的数据。

            问: 老师，copyonwriteArrayList的读没有加锁，为什么还是线程安全的呢？
                public E get(int index) {
                   return get(getArray(), index);
                }
               当一个线程copyonwriteArrayList调用add(int index, E element)时，另一个线程读的时候是原来的数组数据，不是脏读了吗？
            答: 你好,CopyOnWriteArrayList不适用于实时读的场景，像拷贝数组、新增元素都需要时间,所以调用一个set操作后,读取到数据可能还是旧的,虽然CopyOnWriteArrayList能做到最终一致性,但是还是没法满足实时性要求。因此如果对实时要求特别高，那么CopyOnWriteArrayList 可能确实不太适合，他主要用于读多写少的情景，这代表实际的写理论上会非常少，而且是通过最终数据的正确来保证线程安全。
            如果任何一个时间点都期望数据是正确的，那么这时候应该考虑使用同步容器，并发容器没法取代同步容器，并发容器更多的是在保证线程安全的大前提下，尽可能提升并发的性能


        J.U.C之AQS
            AQS全名：AbstractQueuedSynchronizer，是并发容器J.U.C（java.lang.concurrent）下locks包内的一个类。它实现了一个FIFO(FirstIn、FisrtOut先进先出)的队列。底层实现的数据结构是一个双向列表。
              Sync queue：同步队列，是一个双向列表。包括head节点和tail节点。head节点主要用作后续的调度。
              Condition queue：非必须，单向列表。当程序中存在cindition的时候才会存在此列表。
            AQS的大致实现思路:
              AQS内部维护了一个CLH队列来管理锁。线程会首先尝试获取锁，如果失败就将当前线程及等待状态等信息包装成一个node节点加入到同步队列sync queue里。
              接着会不断的循环尝试获取锁，条件是当前节点为head的直接后继才会尝试。如果失败就会阻塞自己直到自己被唤醒。而当持有锁的线程释放锁的时候，会唤醒队列中的后继线程。


        J.U.C之AQS--CountDownlatch

            CountDownLatch，通过给定的计数器数值为其初始化，该计数器是原子性操作，保证同时只有一个线程去操作该计数器。调用该类await方法的线程会一直处于阻塞状态。只有其他线程调用countDown方法（每次使计数器-1）,使计数器归零(即其他方法都执行完)才能继续执行。
                CountDownLatch countDownLatch = new CountDownLatch(200);
                countDownLatch.countDown();
                countDownLatch.await();
            CountDownLatch的await方法还有重载形式，可以设置等待的时间，主线程到这里先阻塞,如果超过此时间，则主线程不继续等待,往下执行(用在某些复杂的功能:要给定执行时间,超过这个时间就算没执行完主线程也要接着往下执行的情况,但是之前的其他多线程也会执行完)：
                countDownLatch.await(10, TimeUnit.MILLISECONDS);

            问: countDownLatch 的作用在哪里呢，保证线程安全吗?
            答: 你好，countDownLatch不是用来做线程安全的，他是一个做线程同步的组件。本质上是可以让主线程在当前阻塞，等待其他线程执行完（通过countDown方法）再继续执行。
            课程里计数的例子添加了countDownLatch的作用：主线程开启了很多线程去运算，希望在所有线程执行完再去打印结果，而countDownLatch就能保证主线程一直阻塞在那里，直到那些线程都执行完。而如果不加这个控制，直接放入线程池就打印，那样可能任务还没调度完，就已经输出count值了，这时候count如果有错，是无法判断是线程不安全导致的，还是线程没都执行完导致的。
            继续说一下实际中我们会在什么场景使用countDownLatch：比如现在有一个任务，需要开启多个线程去处理，然后在任务执行完去做后面的事情。这时候，要保证开启多个线程都处理完再继续后面的操作，就需要借助countDownLatch了。


        J.U.C之AQS--Semaphore

            保证同一时刻并发访问的线程数目,用于仅能提供有限个数的访问资源,比如数据库的有效连接个数.
            final Semaphore semaphore = new Semaphore(3);
            semaphore.acquire();
            test();
            semaphore.release();

            如果并发特别多,需要丢弃一部分许可:
            1.semaphore.tryAcquire()尝试获取一个许可.未得到许可的丢弃.
            2.semaphore.tryAcquire(5000, TimeUnit.MILLISECONDS)  尝试获取许可一段时间，未得到许可的线程丢失

            注意: 测试代码不用@test，改成用main主方法，JUnit在进行单元测试的时候，如果被@Test注释的方法执行完成，那么内部开启的线程也会被强制退出，退出是测试框架进行的操作。

            问: 老师，Semaphore和RateLimiter根据他们的特性，都是可以用来限制并发，那么这两者有什么区别呢？
            答: 你好，Semaphore：信号量，直译很难理解。作用是限定只有抢到信号的线程才能执行，其他的都得等待！你可以设置N个信号，这样最多可以有N个线程同时执行。注意，其他的线程也在，只是挂起了.RateLimiter是guava的，直译是速率限制器。其作用是 限制一秒内只能有N个线程执行，超过了就只能等待下一秒。注意，N是double类型。前者控制的是同一时刻同时运行的线程数目，后者控制的是1s内允许执行的次数，效果上是不同的。
            问: 那假设要执行10万次数据库插入操作，使用RateLimiter进行限制，每秒运行执行300次，那么10万次操作在一秒内并发执行的的时候，剩余的99700次操作是不是会被丢弃？
            答: 可以控制丢弃或者慢慢处理.
            问: 如果有的话应该也是通过acquire或者tryAcquire来区别的吧，我看到Semaphore和RateLimiter都有这两个方法。那么，老师，如果要在某个数据库方法内限制执行次数，是不是使用RateLimiter更合理？
            答: 嗯，是的，控制1s内处理的个数，使用信号量的话，可能处理的特别快，导致短时间内入库太多数据，直接出现主从延迟变大等情况。


        J.U.C之AQS--CyclicBarrier:

        	多线程计算数据,最后合并计算结果的.

        	catchDownLatch:一个或者n个线程等待其他线程执行完才能继续执行. 计数器只能用一次.
        	CyclicBarrier:多个线程相互等待,直到所有的线程满足条件以后才继续执行.每当有一个线程执行了await方法，计数器就会执行+1操作，待计数器达到预定的值，所有的线程再同时继续执行。由于计数器释放之后可以重用（reset方法），所以称之为循环屏障。计数器可以重复使用.

        	barrier.await(2000,TimeUnit.MILLISECONDS); 会抛出异常,需要try-catch捕获,如果不捕获的话会影响下面的程序执行
        	try{
        		barrier.await(2000, TimeUnit.MILLISECONDS);
        	} catch (Exception e) {
        		log.warn("BarrierException" ,e)
        	}
        	log.info("{} continue" , threadNum);
        	CycliBarrier barrier = new CyclicBarrier(5 , () -> {
        		log.info("callback is running");
        	}) 进入屏障后(满足有5个线程await),优先执行runnable.


       	J.U.C之AQS--ReentrantLock
       	  java中有两类锁，一类是Synchronized，而另一类就是J.U.C中提供的锁。ReentrantLock与Synchronized都是可重入锁，本质上都是lock与unlock的操作。接下来我们介绍三种J.U.C中的锁，其中 ReentrantLock使用synchronized与之比对介绍。

       	  ReentrantLock与synchronized的区别:
       	  	``可重入性：两者的锁都是可重入的，差别不大，有线程进入锁，计数器自增1，等下降为0时才可以释放锁
		    ``锁的实现：synchronized是基于JVM实现的（用户很难见到，无法了解其实现），ReentrantLock是JDK实现的。
			``性能区别：在最初的时候，二者的性能差别差很多，当synchronized引入了偏向锁、轻量级锁（自选锁）后，二者的性能差别不大，官方推荐synchronized（写法更容易、在优化时其实是借用了ReentrantLock的CAS技术，试图在用户态就把问题解决，避免进入内核态造成线程阻塞）
			``功能区别：
			（1）便利性：synchronized更便利，它是由编译器保证加锁与释放。ReentrantLock是需要手动释放锁，所以为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。
			（2）锁的细粒度和灵活度，ReentrantLock优于synchronized

		  ReentrantLock独有的功能:
		  	``可以指定是公平锁还是非公平锁(在new对象时可以指定),sync只能是非公平锁.（所谓公平锁就是先等待的线程先获得锁）
			``提供了一个Condition类，可以分组唤醒需要唤醒的线程.不像是synchronized要么随机唤醒一个线程，要么全部唤醒。
			``提供能够中断等待锁的线程的机制，通过lock.lockInterruptibly()实现，这种机制ReentrantLock是一种自选锁，通过循环调用CAS操作来实现加锁。性能比较好的原因是避免了进入内核态的阻塞状态。

		  Condition的使用:
		  	Condition可以非常灵活的操作线程的唤醒，下面是一个线程等待与唤醒的例子，其中用1234序号标出了日志输出顺序:
		  	public static void main(String[] args) {
		  	ReentrantLock reentrantLock = new ReentrantLock();
		  	Condition condition = reentrantLock.newCondition();//创建condition
		  	//线程1
		  	new Thread(() -> {
		        try {
			            reentrantLock.lock();
			            log.info("wait signal"); // 1
			            condition.await();
			        } catch (InterruptedException e) {
			            e.printStackTrace();
			        }
			        log.info("get signal"); // 4
			        reentrantLock.unlock();
			    }).start();
			//线程2
		    new Thread(() -> {
		        reentrantLock.lock();
		        log.info("get lock"); // 2
		        try {
		            Thread.sleep(3000);
		        } catch (InterruptedException e) {
		            e.printStackTrace();
		        }
		        condition.signalAll();//发送信号
		        log.info("send signal"); // 3
		        reentrantLock.unlock();
		   		}).start();
			}

			输出过程讲解：
			1、线程1调用了reentrantLock.lock()，线程进入AQS等待队列，输出1号log
			2、接着调用了awiat方法，线程从AQS队列中移除，锁释放，直接加入condition的等待队列中
			3、线程2因为线程1释放了锁，拿到了锁，输出2号log
			4、线程2执行condition.signalAll()发送信号，输出3号log
			5、condition队列中线程1的节点接收到信号，从condition队列中拿出来放入到了AQS的等待队列,这时线程1并没有被唤醒。
			6、线程2调用unlock释放锁，因为AQS队列中只有线程1，因此AQS释放锁按照从头到尾的顺序，唤醒线程1
			7、线程1继续执行，输出4号log，并进行unlock操作。

       	  读写锁：ReentrantReadWriteLock读写锁
       		在没有任何读写锁的时候才能实现写入操作,悲观读取,在获取写入锁的时候,不允许有任何读锁还保持.如果读多写少的话会导致写锁饥饿,因为读锁一直被使用,写锁无法执行.
       		 private final Lock readLock = lock.readLock();//读锁
    		 private final Lock writeLock = lock.writeLock();//写锁

       	  票据锁：StempedLock
       	  	它控制锁有三种模式（写、读、乐观读）。一个StempedLock的状态是由版本和模式两个部分组成。锁获取方法返回一个数字作为票据（stamp），他用相应的锁状态表示并控制相关的访问。数字0表示没有写锁被锁写访问，在读锁上分为悲观锁和乐观锁。
       	  	乐观读：如果读的操作很多写的很少，我们可以乐观的认为读的操作与写的操作同时发生的情况很少，因此不悲观的使用完全的读取锁定。程序可以查看读取资料之后是否遭到写入资料的变更，再采取之后的措施。

       	  synchronized锁:在JVM层面实现锁定,JVM会替我们释放锁定.
       	  ReentrantLock,ReentrantReadWriteLock,StampedLock: 是对象层面的锁定,要保证锁一定会被释放就需要将解锁其放在finally里面,不然会死锁.
       	  StampedLock对吞吐量有巨大的改进,特别是在读线程越来越多的场景下.

       	  如何选择锁?:
       	  1、当只有少量竞争者，使用synchronized
		  2、竞争者不少但是线程增长的趋势是能预估的，使用ReetrantLock
		  3、synchronized不会造成死锁，jvm会自动释放死锁。

		  问: 老师，为什么加锁释放锁本身可以是安全的？另外，假若面试时，被问到锁机制的底层是怎么实现的，我该怎么说比较好，毕竟锁的类别也很多。。
		  答: 你这里说的锁应该都是针对ReentrantLock这种独享锁，他的安全主要提现在一旦加锁，就只有一个线程可以通过，相当于单线程操作，因此可以保证安全。
		  对于面试中问到，可以这样去回答：课程里介绍了三类锁，核心代表是 synchronized、AtomicXXX、ReentrantLock
		  synchronized属于java提供的关键字，他的实现是借助于cpu指令的字节码来实现的。
		  AtomicXXX本质上其实不是锁，而是通过CAS自旋（循环尝试去更新，直至成功)与volatile变量互相配合来保证线程安全的更新
		  ReentrantLock则是基于AQS进行的实现，核心是借助里面CLH队列实现锁的排队策略

		  问: 多线程的代码是如何调试的?
		  答: 我们调试只能看单线程的内容，会影响多线程的执行.
		  实际开发中，我们做多线程处理时，对输出的log讲究很多,核心环节必须输出log及相关变量值。一个配置好的log在做输出时，通常会包含时间及线程名，真出问题时，需要找到相关的日志，然后分析线程的运行情况，确定问题根本原因。
		  这也说明，log的记录很重要。

		  面试题: 对象锁和类锁的区别?
		  答: 对象锁锁的是这个类的某一个对象,类锁锁的是这个类的所有对象
		  作用于调用的对象:多个线程同时执行同一个对象的example01.test()时,是一个先执行完再执行下一个.多个线程同时执行该类的两个对象example01.test(),example02.test(),结果是两个方法交替执行.
	   	  作用于调用的类:这个类的不同对象多线程执行方法,都是先执行完一个再执行下一个.

		  注意: 不要使用system.out的打印结果来验证多线程的输出结果，请使用课程里介绍的log或者自己定义一个log。你这样输出的结果是无法具体确认是哪个线程执行的，尤其是你要分析的内容与哪个线程执行有关，而log在输出日志则会带上时间和实际执行的线程，这两项对结果的分析至关重要。


    J.U.C--FutureTask

		  FutureTask是J.U.C中的类，是一个可删除的异步计算类。这个类提供了Future接口的的基本实现，使用相关方法启动和取消计算，查询计算是否完成，并检索计算结果。只有在计算完成时才能使用get方法检索结果;如果计算尚未完成，get方法将会阻塞。一旦计算完成，计算就不能重新启动或取消(除非使用runAndReset方法调用计算)。

		  new Thread()和Runnable()的缺点:线程执行完之后无法获取返回值,Java1.5之后就提供了Callable与Future，这两个接口就可以实现获取任务执行结果

		  Future接口:FutrueExample
		  FutureTask实现了RunnableFuture接口，而RunnableFuture接口继承了Runnable与Future接口，所以它既可以作为Runnable被线程中执行，又可以作为callable获得返回值。

		  问: 同样的代码，为什么我的代码先执行的do something in main， 后执行的do something in callable呢？这个和线程优先级有关系吗？
          答: 当前线程额外启动了一个线程，这时当前线程和额外启动的线程由于受CPU调度的影响，执行先后并不是完全确定的，你如果多执行几次，应该也会出现我课程演示时相同的结果。不过有一点可以肯定的是，发生这种情况时，大家执行的时间都会非常的接近，应该是毫秒级别相差无几。这个例子也说明了一个问题，就是两个线程定义的先后顺序决定不了执行的顺序。


	J.U.C--Fork/Join框架

        ForkJoin是Java7提供的一个并行执行任务的框架，是把大任务分割成若干个小任务，待小任务完成后将结果汇总成大任务结果的框架。主要采用的是工作窃取算法，工作窃取算法是指某个线程从其他队列里窃取任务来执行。
        在窃取过程中两个线程会访问同一个队列，为了减少窃取任务线程和被窃取任务线程之间的竞争，通常我们会使用双端队列来实现工作窃取算法。被窃取任务的线程永远从队列的头部拿取任务，窃取任务的线程从队列尾部拿取任务。

        局限性:
        1、任务只能使用fork和join作为同步机制，如果使用了其他同步机制，当他们在同步操作时，工作线程就不能执行其他任务了。比如在fork框架使任务进入了睡眠，那么在睡眠期间内在执行这个任务的线程将不会执行其他任务了。
        2、我们所拆分的任务不应该去执行IO操作，如读和写数据文件。
        3、任务不能抛出检查异常。必须通过必要的代码来处理他们。

        框架核心:
        核心有两个类：ForkJoinPool | ForkJoinTask
        ForkJoinPool：负责来做实现，包括工作窃取算法、管理工作线程和提供关于任务的状态以及他们的执行信息。
        ForkJoinTask:提供在任务中执行fork和join的机制。


        问: mapreduce与fork join区别 ？查了一些相关资料但是还是比较懵逼  比较不出优略。或者说各自的优势
        答: map reduce与fork join区别 。他俩最大的区别是，fork join主要是在一个jvm上进行使用的，而map reduce是明确设计为在集群上工作。同时呢,forkjoin是将任务分割成多个子任务的，以递归的方式，可以有很多层，更充分地利用内核；map reduce 则是做一个大的分裂，单层，分裂之后互相之间没有通信，并可大规模扩展.

        问: fork join 与 与多线程操作然后等待主线程统一返回有什么区别?
        答: fork join主要是不断拆分自己的任务，主要是为了完成同一个任务。而主线程等待子线程可以是不同的任务，只是在保证都结束后再继续后面的操作。在计算单一任务时，fork join会更有优势。

        问: Semaphore与newCachedThreadPool联合使用与 newFixedThreadPool的区别,Semaphore与newCachedThreadPool联合使用的目的是为了防止无限的消耗内存？但是直接用newFixedThreadPool或者说直接手动写一个线程池，定义一个有界队列哪怕把队列值写的很大也是可以的啊?
        答: 线程池控制的是线程数量，而信号量控制的是并发数量，虽然说这个看起来一样，但是还是有区别的.信号量的调用，当达到数量后，线程还是存在的，只是被挂起了而已。而线程池，同时执行的线程数量是固定的，超过了数量的只能等待。

        问: 老师 , 我在学习ForkJoin的时候看到了廖雪峰老师的一篇文章 , 不知道老师有没有看过这篇文章 , 链接在这里 https://www.liaoxuefeng.com/article/001493522711597674607c7f4f346628a76145477e2ff82000  他在文章中提到 我们在课程中的实例不妥 ,他认为我们的这种写法不符合Fork/Join模型的任务执行逻辑, 老师怎么看 ,还是说我对两位老师的代码示例理解有误 ,他在文章中使用的 invoke 提交 task 的 , 我搜索了一下别人对invoke和submit 的解释,感觉都不是很明白,我想问问invoke和submit有什么区别 ,什么情况下适合使用submit , 什么情况下适合使用invoke ?
        答: 你好，先说第一个问题，使用fork方法不是最高效的，这个确实如此，关于这个问题，网上很多文章也在说，比如：https://blog.csdn.net/cxl0921/article/details/76460909  ，https://www.cnblogs.com/Redvelvet/p/4918307.html。那么，既然fork不是最高效的，为什么还要用他来举例子呢，就ForkJoin而言，直接使用fork、join两个方法来举例子大家更容易理解也更容易记住他。提到ForkJoin，你可能直接就会想起这两个方法以及能解决的问题。随着学习的深入，invokeAll就出现了，相比fork，他可以更好的利用线程池，实际表现也更好。因为ForkJoin大家平时用的并不多，因此课程在ForkJoin这里没打算讲太多的细节，不过，课程里如果直接给出invokeAll的对比，效果应该会更好些。
        再来说一下这里submit和invoke的区别。invoke是同步执行，调用之后需要等待任务完成，才能执行后面的代码；submit是异步执行，只有在Future调用get的时候会阻塞。

    J.U.C--BlockingQueue
        有完整队列的基本功能,同时在多线程环境下,他还能自动管理多线程的线程等待,唤醒,便于开发.
        主要应用场景：生产者消费者模型，是线程安全的
        阻塞情况:
            1、当队列满了进行入队操作
            2、当队列空了的时候进行出队列操作
        实现类:
            1.	ArrayBlockingQueue：它是一个有界的阻塞队列，内部实现是数组，初始化时指定容量大小，一旦指定大小就不能再变。采用FIFO方式存储元素。
            2. DelayQueue：阻塞内部元素，内部元素必须实现Delayed接口，Delayed接口又继承了Comparable接口，原因在于DelayQueue内部元素需要排序，一般情况按过期时间优先级排序。
            3. LinkedBlockingQueue：大小配置可选，如果初始化时指定了大小，那么它就是有边界的。不指定就无边界（最大整型值）。内部实现是链表，采用FIFO形式保存数据。
            4. PriorityBlockingQueue:带优先级的阻塞队列。无边界队列，允许插入null。插入的对象必须实现Comparator接口，队列优先级的排序规则就是按照我们对Comparable接口的实现来指定的。我们可以从PriorityBlockingQueue中获取一个迭代器，但这个迭代器并不保证能按照优先级的顺序进行迭代。
            5. SynchronusQueue：只能插入一个元素，同步队列，无界非缓存队列，不存储元素。

        注:executor.newCachedThreadPool(),看似是无边界的,其实他的边界是整型Integer的最大值.(详见源码)


    线程池:

        new Thread的弊端:
        1. 每次new Thread 新建对象，性能差
        2. 线程缺乏统一管理，可能无限制的新建线程，相互竞争，可能占用过多的系统资源导致死机或者OOM（out of memory 内存溢出），这种问题的原因不是因为单纯的new一个Thread，而是可能因为程序的bug或者设计上的缺陷导致不断new Thread造成的。
        3. 缺少更多功能，如更多执行、定期执行、线程中断。

        线程池的好处:
        1. 重用存在的线程，减少对象创建、消亡的开销，性能好
        2. 可有效控制最大并发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞。
        3. 提供定时执行、定期执行、单线程、并发数控制等功能。

        线程池核心类--ThreadPoolExecutor
        参数说明: ThreadPoolExecutor一共有七个参数，这七个参数配合起来，构成了线程池强大的功能。
        1. corePoolSize: 核心线程数量
        2. maxmumPoolSize: 线程最大线程数
        3. workQueue: 阻塞队列, 存储等待执行的任务,很重要, 会对线程池运行过程产生重大影响.

            当我们提交一个新的任务到线程池，线程池会根据当前池中正在运行的线程数量来决定该任务的处理方式。处理方式有三种：
            1、直接切换（SynchronusQueue）
            2、无界队列（LinkedBlockingQueue）能够创建的最大线程数为corePoolSize,这时maximumPoolSize就不会起作用了。当线程池中所有的核心线程都是运行状态的时候，新的任务提交就会放入等待队列中。
            3、有界队列（ArrayBlockingQueue）最大maximumPoolSize，能够降低资源消耗，但是这种方式使得线程池对线程调度变的更困难。因为线程池与队列容量都是有限的。所以想让线程池的吞吐率和处理任务达到一个合理的范围，又想使我们的线程调度相对简单，并且还尽可能降低资源的消耗，我们就需要合理的限制这两个数量

            分配技巧:
             如果想降低资源的消耗包括降低cpu使用率、操作系统资源的消耗、上下文切换的开销等等，可以设置一个较大的队列容量和较小的线程池容量，这样会降低线程池的吞吐量。如果我们提交的任务经常发生阻塞，我们可以调整maximumPoolSize。如果我们的队列容量较小，我们需要把线程池大小设置的大一些，这样cpu的使用率相对来说会高一些。但是如果线程池的容量设置的过大，提高任务的数量过多的时候，并发量会增加，那么线程之间的调度就是一个需要考虑的问题。这样反而可能会降低处理任务的吞吐量。

        4. keepAliveTime: 线程没有任务执行时最多保持多久时间终止（当线程中的线程数量大于corePoolSize的时候，如果这时没有新的任务提交核心线程外的线程不会立即销毁，而是等待，直到超过keepAliveTime）
        5. unit: keepAliveTime的时间单位
        6. threadFactory: 线程工厂，用来创建线程，有一个默认的工场来创建线程，这样新创建出来的线程有相同的优先级，是非守护线程、设置好了名称.
        7. rejectHandler: 当拒绝处理任务时(阻塞队列满)的策略（AbortPolicy默认策略直接抛出异常、CallerRunsPolicy用调用者所在的线程执行任务、DiscardOldestPolicy丢弃队列中最靠前的任务并执行当前任务、DiscardPolicy直接丢弃当前任务）

        corePoolSize、maximumPoolSize、workQueue 三者关系：
        1）如果此时线程池中的数量小于 corePoolSize（核心池的大小） ， 即使线程池中的线程都处于空闲状态， 也要创建新的线程来处理被添加的任务（也就是每来一个任务， 就要创建一个线程来执行任务） 。
        2）如果此时线程池中的数量大于等于 corePoolSize， 但是缓冲队列workQueue 未满， 那么任务被放入缓冲队列， 则该任务会等待空闲线程将其取出去执行。
        3）如果此时线程池中的数量大于等于 corePoolSize ， 缓冲队列workQueue 满， 并且线程池中的数量小于 maximumPoolSize（线程池最大线程数） ， 建新的线程来处理被添加的任务。
        4）如果此时线程池中的数量大于等于 corePoolSize， 缓冲队列workQueue 满， 并且线程池中的数量等于 maximumPoolSize， 那么通过RejectedExecutionHandler 所指定的策略(任务拒绝策略)来处理此任务。也就是处理任务的优先级为： 核心线程 corePoolSize、 任务队列workQueue、 最大线程 maximumPoolSize， 如果三者都满了， 使用handler 处理被拒绝的任务。
        特别注意， 在 corePoolSize 和 maximumPoolSize 之间的线程数会被自动释放。 当线程池中线程数量大于 corePoolSize 时， 如果某线程空闲时间超过 keepAliveTime， 线程将被终止， 直至线程池中的线程数目不大于 corePoolSize。 这样， 线程池可以动态的调整池中的线程数。

        项目开启多少个线程的问题:
        当我不知道一个新环境我可以用多少个线程，而又想尽可能快的完成时，我也会选择从10开始，每次10个递增去尝试，看应用的表现，这样相对安全很多。你可以会认为每次调整都要发布重新部署，我们通常会预置一个开关代替线程数，然后每次测试时只需要动态的去修正这个开关配置的数值就可以了，不断的调整到最佳。这个验证过程中，也要考虑应用高峰和低峰的时间段，和本身启动多线程处理时间段的对比。
        对于任何一个应用，可以启动多少个线程都是不一样的，在寻找最佳线程数的时候，需要优先保证应用的“安全”，但一定不要一开始就给一个特别大的线程数，这样不但可能完成不了，反而可能直接让项目出现各种问题。

        线程池的方法:
        execute(): 提交任务，交给线程池执行
        submit(): 提交任务，能够返回执行结果 execute+Future
        shutdown(): 关闭线程池，等待任务都执行完
        shutdownNow(): 关闭线程池，不等待任务执行完
        getTaskCount(): 线程池已执行和未执行的任务总数
        getCompleteTaskCount(): 已完成的任务数量
        getPoolSize(): 线程池当前的线程数量
        getActiveCount(): 当前线程池中正在执行任务的线程数量
        这四个get方法可以用来监控线程池的运行状况

        使用Executor创建线程池:
        1. newCachedThreadPool
           创建一个可缓存的线程池，如果线程池的长度超过了处理的需要，可以灵活回收空闲线程。如果没有可回收的就新建线程。
           public static ExecutorService newCachedThreadPool() {
             return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                           60L,TimeUnit.SECONDS,
                                           new SynchronousQueue<Runnable>());
           }

           注意: newCachedThreadPool的返回值是ExecutorService类型，该类型只包含基础的线程池方法，但却不包含线程监控相关方法，因此在使用返回值为ExecutorService的线程池类型创建新线程时要考虑到具体情况。

        2. newFixedThreadPool
           定长线程池，可以线程现成的最大并发数，超出在队列等待.
           public static ExecutorService newFixedThreadPool(int nThreads) {
             return new ThreadPoolExecutor(nThreads, nThreads,
                                           0L, TimeUnit.MILLISECONDS,
                                           new LinkedBlockingQueue<Runnable>());
           }

        3. newSingleThreadExecutor
           单线程化的线程池，用唯一的一个共用线程执行任务，保证所有任务按指定顺序执行（FIFO、优先级…）.
           public static ExecutorService newSingleThreadExecutor() {
             return new FinalizableDelegatedExecutorService
                    (new ThreadPoolExecutor(1, 1,
                                            0L, TimeUnit.MILLISECONDS,
                                            new LinkedBlockingQueue<Runnable>()));
           }

        4. newScheduledThreadPool
           定长线程池，支持定时和周期任务执行
           public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) {
             return new ScheduledThreadPoolExecutor(corePoolSize);
           }
           public ScheduledThreadPoolExecutor(int corePoolSize) {
             super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,     //此处super指的是ThreadPoolExecutor
                   new DelayedWorkQueue());
           }

           scheduleAtFixedRate : 按指定频率周期执行某个任务。
           例如:
            executor.scheduleAtFixedRate(new EchoServer(),0,100,TimeUnit.MILLISECONDS);
            初始化延迟0ms开始执行，每隔100ms重新执行一次任务。当执行任务的时间大于我们指定的间隔时间时，它并不会在指定间隔时开辟一个新的线程并发执行这个任务。而是等待该线程执行完毕。
            需要注意的，我们需要捕获最上层的异常，防止出现异常中止执行，导致周期性的任务不再执行。

           scheduleWithFixedDelay : 按指定频率间隔执行某个任务。
           例如:
            executor.scheduleWithFixedDelay(new EchoServer(),0,100,TimeUnit.MILLISECONDS);
            初始化时延时0ms开始执行,本次执行结束后延迟100ms开始下次执行。

           小扩展：延迟执行任务的操作，java中还有Timer类同样可以实现
           Timer timer = new Timer();
           timer.schedule(new TimerTask() {
                @Override public void run() {
                    log.warn("timer run");
                }
           }, new Date(), 5 * 1000);
           定时任务, 从当前时间开始执行, 每5s执行一次

        注意: 当线程池中的每个任务很小时,小到任务计算的时间和线程调度的时间很接近时,这时用线程池反而会慢,因为资源太多被用在线程调度



        问: 开启100个线程,做一些查询和添加操作,由于环境问题（测试环境在外网）和带宽问题（每人限制只有1M带宽）会发生很多超时错误，所以想你给点意见，这段代码大体上结构有问题吗?

            //这里会循环100次
            for (Date date : concurrentSet) {
                //每天一个线程处理
                executorService.execute(() -> {
                    //一些查询操作
                    xxxService.select();
                    //还有一些添加操作
                    xxxService.batchInsert();
            }
        答:
        你好，说一下我的想法，100个线程有点多，而且是对数据库的操作，感觉这个线程数目可能已经超过了你数据库连接池配置的连接数目了，这直接会带来这么多线程，即使是同步执行，也很多会阻塞在数据库连接那里，并出现或许数据库连接失败的异常。这是第一个问题。
        第二个问题，数据库资源通常是项目里最紧缺的，这里过分消耗，可能会导致那个时间点其他功能受影响。数据库连接是一方面，即使能拿到连接，同时进行大量的操作，数据库的压力也会突然变大。如果数据库要做主从同步，还可能造成同步的延迟。
        第三个问题，不知道你目前这样操作，一次select() 和 batchInsert() 数据量有多大，如果很大的话，1M的带宽可能直接打满，导致项目无法对外提供功能。而如果很小的话，线程数少一些，也会做的特别快。
        第四个问题，你也提到了1M的带宽，这个限制确实不适合过多线程同时执行。说到这里，你可以在本地启动10个线程、20个线程、30个线程去做些测试，对比一下10到20、20到30这个过程中内存、CPU等的变化。你基本上可以大致评估达到100个线程的影响。

        问: web应用中线程池是设置为成员变量还是局部变量?
        答: 基本上很少使用局部变量声明的线程池，每次处理时都生成一个线程池再销毁，这个代价实在太大了，而且如果请求多的时候，可能同一时间创建大量的线程池，导致应用直接不可用。成员变量声明的线程池，若不是常用的服务模块，那感觉基本没有使用线程池的必要。
        问: 成员变量的线程池,如何保证在应用停止时,正常的线程任务都执行完, 我想到的时若是spring 声明的 bean,可以在bean destroy时调用 pool.shutdown, 但若应用是异常停止(比如kill),如何保证?
        答: 这个问题倒是蛮不错，其实应用停止时，jvm时提供了扩展允许你做些事情的。我给你提供个方法，你自己去了解下吧，这种写法成为“JVM钩子”。具体代码为：
        Runtime.getRuntime().addShutdownHook(new Thread() {
            @Override
            public void run() {
            // do something when jvm shutdown
            }
        });



        死锁

        通俗的说，死锁就是两个或者多个线程，相互占用对方需要的资源，而都不进行释放，导致彼此之间都相互等待对方释放资源，产生了无限制等待的现象。死锁一旦发生，如果没有外力介入，这种等待将永远存在，从而对程序产生严重影响。

        死锁产生的必要条件:
          互斥条件：一个线程已经得到锁,对锁分配的资源进行排他性使用
          请求和保持条件：线程已经保持了一个资源，但是又提出了其他请求，而该资源已被其他线程占用
          不剥夺条件：在使用时不能被剥夺，只能自己用完释放
          环路等待条件：资源互相调用是一个环形的链

        确认死锁:
          在真实的环境中，我们发现程序无法执行，并且CPU占用为0，这样就有理由怀疑产生了死锁，但是光怀疑是不行的，我们需要一个实际的验证方法。接下来我们使用jdk提供的工具来检测是否真正发生了死锁。
          运行上述死锁例子的代码，并在windows系统中使用cmd进入控制台，
          1.输入以下命令：jps , 得到该进程的id
          2.jstack 9284   ,  获取该进程对应的堆栈信息
          3.发现两个线程都进行了加锁操作,同时系统发现了一个Java-level的线程死锁。确认无疑是发生了死锁现象。

        避免死锁:
          1.注意加上顺序
          2.使用加锁时限(超过时限放弃加锁)
          3.死锁检测



	并发最佳实践:
		1.使用本地变量:
		2.使用不可变类
		3.最小化锁的作用域范围: S=1/(1-a+a/n)  a:并行计算部分所占的比例 n:并行处理的节点个数 S:代表加速比
		a=0时,S=1,表示只有串行,没有并行; a=1时,S=n,表示只有并行,没有串行;
		n->∞时,S->1/(1-a),即加速比的上线.
		所以上锁和解锁的代码越小越好.
		4.使用线程池的Executor,而不是直接使用new Thread执行.
		5.宁可使用同步(catchDownLatch和semphore)也不要使用线程的wait和notify.
		6.使用Blocking Queue实现生产-消费模式
		7.使用并发集合(copyOnWriteArrayList,copyOnWriteSet,concurrentHashMap等)而不是加了锁的同步集合
		8.使用Semaphore创建有界的访问(比如数据库连接,socket连接,需要控制访问数量)
		9.宁可使用同步代码块,也不实用同步的方法
		10.避免使用静态变量(如果必须用,可以将其变为final,如果是集合的话可以考虑用只读集合)

	问: 在使用completionService， countDownLatch， semaphore等并发工具的时候， 经常与到检查型异常InterruptedException。
	这个异常应该如何处理呢， 是分别try catch， 还是用throws的方式汇总的一起处理， 需要使用Thread.currentThread().interrupt();这样的结构去显示地中断线程吗？
	答: 你好，一个线程不是可以随便中断的。即使我们给线程设置了中断状态，它也还是可以获得CPU时间片的。通常只有因为sleep()方法而阻塞的线程可以立即收到InterruptedException异常，所以在sleep中断任务的情况下可以直接使用try-catch跳出任务。其它情况下，需要通过判断线程状态来判断是否需要跳出任务(Thread.interrupted()方法)。
	另外，synchronized方法修饰的代码不会在收到中断信号后立即中断。ReentrantLock锁控制的同步代码可以通过InterruptException中断。
    Thread.interrupted方法调用一次之后会立即清空中断状态。可以自己用变量保存状态。但这个方法目前已经用的很少了，J.U.C里提供的组件已经可以处理绝大部分的场景了

    Spring与线程安全
  	spring的bean对象能做到线程安全是因为bean对象是无状态的,不存在多个线程去修改同一个状态的问题.

  	问: 对无状态对象理解比较迷茫，什么是有状态的变量或者类？？能举一个具体的栗子吗？？
  	答: 你好，有状态就是有数据存储功能。有状态对象(Stateful Bean)，就是有实例变量的对象，可以保存数据，是非线程安全的。代码举例：

	/**
	 * 有状态bean,有state,user等属性，并且user有存偖功能，是可变的。
	 */
	public class StatefulBean {
	    public int state;
	    // 由于多线程环境下，user是引用对象，是非线程安全的
	    public User user;
	    public int getState() {
	        return state;
	    }
	    public void setState(int state) {
	        this.state = state;
	    }
	    public User getUser() {
	        return user;
	    }
	    public void setUser(User user) {
	        this.user = user;
	    }
	}

	无状态主要是一次操作，不能保存数据。无状态对象(Stateless Bean)，就是没有实例变量的对象.不能保存数据，是不变类，是线程安全的。代码举例：
	/**
	 * 无状态bean,不能存偖数据。因为没有任何属性，所以是不可变的。只有一系统的方法操作。
	 */
	public class StatelessBeanService {
	    // 虽然有billDao属性，但billDao是没有状态信息的，是Stateless Bean.
	    BillDao billDao;
	    public BillDao getBillDao() {
	        return billDao;
	    }
	    public void setBillDao(BillDao billDao) {
	        this.billDao = billDao;
	    }
	    public List<User> findUser(String Id) {
	         return null;
	    }
	}


	HashMap与ConcurrentHashMap
	hashMap: 通过数组与指针(引用)实现的
	性能受两个参数的影响: 初始容量,加载因子
	初始容量默认16,加载因子默认0.75f

	hashMap数组的容量值必须是2^n? 因为取模的代价远高于位操作代价,在计算index时将key的hash值对2^(n-1)进行与运算,其结果与取模操作是完全相同的,所以用取与不用取模.hashMap会在初始化容量时根据用户的传入通过位运算计算出2^n的容量,不需要用户自己传入.

	hashMap的线程不安全主要体现在?
	resize()时可能出现死循环, 以及在迭代过程中出现fast-fail错误: (快速失败机制，是Java集合(Collection)中的一种错误检测机制。在迭代集合的过程中该集合在结构上发生改变的时候，就有可能会发生fast-fail，即抛出ConcurrentModificationException异常。fast-fail机制并不保证在异步修改一定会抛出异常，它只是尽最大努力去抛出，所以这种机制一般仅用于检测bug。)
	扩容时出现死循环: hashMap的数组容量达到(容量*扩容因子)时会触发resize()来扩容,会首先创建一个2倍于原容量的新数组,然后将原先数组中的元素重新rehash()计算index来放入新的数组.在多线程环境下,这个过程中容易出现死循环,即在两个元素之间来回循环执行rehash(),导致后面的元素不能rehash();(详细可参见9-4,3:30处)

	ConcurrentHashMap(详见concurrentHashMap的结构图):
	conCurrentHasMap最外层是一个Segment的大的数组,每个Segment包含一个与hashMap差不多的链表数组.现根据哈希码高sshit位决定Segment数组的index,接下来操作Segment与操作hashMap一样.Segemnt继承自ReentrantLock的,可以很方便地对每一个Segment进行锁相关的处理.
	ConcurrentHashMap与HashMap的不同:
	1.ConcurrentHashMap线程安全,HashMap线程不安全
	2.ConcurrentHashMap不允许key和value为空,而HashMap允许.
	3.HashMap不允许iterator遍历时更新,而ConcurrentHashMap允许,并且更新对后续的更新是可见的.

	Java8为了提高ConcurrentHashMap的并发性,废弃了Segment分段锁,采用了一个大的数组,若链表长度超过一定长度(默认为8)将链表改为红黑树,寻址复杂度有o(n)转变为o(logn).HashMap中页同样的引入了红黑树.
	ConcurrentHashMap源码分析: https://blog.csdn.net/u010412719/article/details/52145145

	注意: 涉及到jdk本身提供的类在调试时都有这个问题，如果断点加的时机不对，就会被其他的数据影响你的调试。你可以尝试着在自己调试的代码前加个log，当这一行log明确执行到的时候，再去底层的类里加上断点。
	关于调试，idea里有个小技巧，可以在调试窗口里临时关掉某些断点，需要时再打开，很好用。对于断点加早了，这样会容易很多，不需要挨个取消，而是进来关闭一下，等走到自己要测试的代码时再打开。

    高并发处理思路与手段:
        扩容:
         垂直扩容: 提高系统部件能力(比如给内存升级)
         水平扩容: 增加更多系统成员(比如增加服务器)

         分布式服务器集群(服务器放在多个机房)+数据库主从架构 --> 异地多活,单元化(见图片)

         如果主库所在的机房出现问题,怎么应对?
            不使用ip+端口的方式直接连数据库,而是通过域名连接,出问题时,DBA主需要调整域名后面对应的机器,让域名映射的主库变为某个从库,可以将影响降到最低.
         异地多活,单元化?
            两个城市单独部署了两个独立的集群,他们提供相同的服务,通过某些机制来完成必要数据的同步,当某一个单元出问题的,可以很快将这个单元的流量切换到另一个单元上,做到最大情况的容灾.

        缓存:
         命中率: 命中数 / (命中数 + 没有命中数)
         最大元素(空间): 缓存中可存放的最大元素的数量
         清空策略 : FIFO(先进先出) , LFU(最少使用) ,LRU(最近最少使用),过期时间,随机

         本地缓存: 编程实现(成员变量,局部变量,静态变量),Guava Cache
         分布式缓存: Memcache , Redis


    高并发场景下缓存的常见问题:

    1.缓存的一致性 : 高并发场景下,数据库中数据与缓存中的数据不同步.
      解决: 加锁 ,   lock--> 查询DB,更新缓存 --> unlock
    2.缓存穿透问题 : key被高并发地访问没有命中,然后高并发请求会去DB查询,而当key对应的值null时,会使数据库进行很多不必要的查询.
      解决: a.缓存空对象,如果是集合的话返回空集合.
            b.单独过滤处理,对有可能对应数据为null的数据统一存放,并在请求进入数据库前做拦截,避免请求进入数据库.
    3.缓存的雪崩现象 : 大量请求进入DB,使得DB崩溃.缓存并发,缓存穿透,缓存抖动,某个时间点,系统预加载的缓存集中失效.
      解决: a.限流,降级,熔断,多级缓存.
            b.设置不同的缓存过期时间.

    Redis在实际股票分时K线图的实践手记:  https://www.imooc.com/article/20918

    问: 之前面试，有被问到，缓存更新的顺序是什么，先更新数据库，还是先删除缓存。
    答: 你好，这个问题，很难找到一种方案能适用于所有的场景，否则早就会一些组件封装出来使用了，而且数据一致性也是所有分布式系统都很难从根本解决的问题，cap原理就放在那，谁都躲不开。
    但实际这个问题确实存在，面试也会问到，其实关键还是考察你是否能根据不同的场景做特定的分析，也看看是否你能给出一些可行的方案。这里说一些手段，你可以感受一下：
    1、更新数据库，异步更新缓存，如果失败，可以选择放入消息队列去更新或删除掉
    2、先更新缓存，如果失败，可以选择放入消息队列去更新或删除掉，再更新数据库。如果数据库更新失败，删除缓存（依旧可以通过多种手段保证删除成功）
    这两点都是通过异步或消息队列的方式保证数据最终一致性，但是需要注意的是，先删除缓存出错时，不能影响主流程数据库更新的操作，本质上缓存是否更新失败都要保证数据库更新进行操作。因此呢，我个人更喜欢先更新数据库，然后借助消息队列等保证缓存里数据和db里的一致，甚至删除缓存保证数据正确。
    3、可以在缓存中考虑加入标记位，先更新缓存时，可以先置标记位为失效状态，等db更新后，再更新缓存数据，并更新标记位为有效。当使用缓存时，记得check标记位就可以了。
    实际中出现这种问题的概率很小，毕竟那些缓存的组件，比如redis，性能都特别好，因此在实际中，我们都默认按照他会成功去处理，然后捕捉住异常，做些补偿性手段，来保证最终的一致性。其实，也没有什么完美的方案，适合自己的场景，代价最小的，就是最好的~


    消息队列
        消息队列的好处：
        1.业务解耦
        2.最终一致性
        3.广播
        4.错峰与流控

    应用拆分
        应用之间的通信： RPC（dubbo等），消息队列，REST
        拆分架构： 服务化Dubbo ， 微服务Spring Cloud

    应用限流
        限流的算法：  详见 http://www.cnblogs.com/clds/p/5850070.html
        1.计数器法
        2.滑动窗口
        3.漏桶算法
        4.令牌桶算法

        Guava RateLimiter使用，用的令牌桶算法。



    问： 老师，限流思想中，可以使用Semphone吗？
    答： 你好，尽管semaphore也能满足你对“限流”的要求，但semaphore本质上是控制同时并行处理的数量，而ratelimiter等限流组件本质上控制一段时间内调用的次数（通常为1s）。
    对于执行特别快的请求，semaphore明显不合适，比如我们为了保护数据库，希望控制每秒访问数据库的次数不超过800，这时使用semaphore就很不合适，你只能控制同时请求的次数，而每次请求耗时差别很大，无法知道1s内具体能查询多少次，每秒间的查询次数也可能差别很大，使用semaphore配置多大都不太合适。

    问： 老师关于tomcat的并发，1.网上说是150-200？可以自己设置，一般200.假设到了200.在没有集群的情况下，tomcat处理是堵塞剩下的链接还是丢弃。。同理mysql又是什么样的呢？2.我们时常说服务量大了服务器会down机？什么是..down机。我用jmeter1秒钟模拟10000个并发都没把一台tomcatp打爆
    答： 你好，我们分别来说你这两个问题。
    1、首先肯定是阻塞的，直接丢弃这个本身对用户体验太差了，实际中我们也不会说丢弃就丢弃，很明显一个例子，我们经常听说系统压力特别大，很多时候就因为并发的线程过多，同时等待的也很多，也会出现这种情况，否则tomcat只处理指定的线程数，那么服务器压力基本上是稳定的。实际中，在处理多线程时，基本都会选择类似于线程池的模式，会有一个阻塞的队列，当线程过多无法处理时，就会放到阻塞队列里，慢慢处理。当然，这种阻塞直接带来的就是处理变慢，如果是tomcat处理过慢时，就会出现用户请求一个接口很久才能返回的情况，甚至超时。这时候，我们通常会选择增加集群里服务器数量，来让请求尽可能的都被处理。
    2、down机，简单的说就是服务器出问题了，无法正常处理请求了。当然这不带代表线程多就会down机，还需要看线程消耗的内存以及每个线程处理的时间等等，你可以尝试把每个线程调整为3s，然后把每个线程消耗的内存增大，而不是最普通的做+1这种操作，你再试试看。





