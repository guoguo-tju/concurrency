	


并发:
	同时拥有两个或者多个线程,如果程序在单核处理器上运行,多个线程交替地换入或者换出内存,这些线程是同时"存在"的,每个线程都处于执行过程中的某个状态,如果运行多核处理器上,此时,程序中每个线程都将分配到一个处理核上,因此,可以同时运行.

CPU多级缓存:
	*为什么需要CPU缓存呢?
	因为CPU的频率太快了,快到主存跟不上,这样在处理器时钟周期内,CPU常常需要等待主存,浪费资源.所以cache的出现,是为了缓解CPU和内存之间速度的不匹配问题(结构:CPU-->cache-->memory)	
	*保证缓存的一致性(MESI协议)
		参考博客: https://blog.csdn.net/muxiqingyang/article/details/6615199
	*乱序执行优化
	处理器为提高运算速度而做出的违背代码原有顺序的优化(重排序).单核的环境下处理结果与预期相同,但多核情况下,多个核来执行指令,每个核都可能被乱序,使得结果偏离预期.
	*Java内存模型(Java Memory Model --JMM)
		`它规定了一个线程如何和何时可以看到其他线程修改过的共享变量的值，以及在必须时如何同步地访问共享变量
		`堆Heap:运行时数据区，有垃圾回收，堆的优势可以动态分配内存大小，生存期也不必事先告诉编译器，因为他是在运行时动态分配内存。缺点是由于运行时动态分配内存，所以存取速度慢一些。
		`栈Stack:优势存取速度快，速度仅次于计算机的寄存器。栈的数据是可以共享的，但是缺点是存在栈中数据的大小与生存期必须是确定的。主要存放基本类型变量，对象据点。要求调用栈和本地变量存放在线程栈上。
		`静态类型变量跟随类的定义存放在堆上。存放在堆上的对象可以被所持有对这个对象引用的线程访问。
		`如果两个线程同时调用了同一个对象的同一个方法，他们都会访问这个对象的成员变量。但是这两个线程都拥有的是该对象的成员变量（局部变量）的私有拷贝。—[线程封闭中的堆栈封闭]
	*计算机硬件架构:
		`CPU Registers(寄存器):是CPU内存的基础，CPU在寄存器上执行操作的速度远大于在主存上执行的速度。这是因为CPU访问寄存器速度远大于主存。
		`CPU Cache Memory(高速缓存):由于计算机的存储设备与处理器的运算速度之间有着几个数量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高级缓存，来作为内存与处理器之间的缓冲。将运算时所使用到的数据复制到缓存中,让运算能快速的进行。当运算结束后，再从缓存同步回内存之中，这样处理器就无需等待缓慢的内存读写了。
		`RAM-Main Memory(主存/内存):当一个CPU需要读取主存的时候，他会将主存中的部分读取到CPU缓存中，甚至他可能将缓存中的部分内容读到他的内部寄存器里面，然后在寄存器中执行操作。当`CPU需要将结果回写到主存的时候，他会将内部寄存器中的值刷新到缓存中，然后在某个时间点从缓存中刷回主存。
	*JMM与硬件架构的关系
		`Java内存模型抽象结构：每个线程都有一个私有的本地内存，本地内存他是java内存模型的一个抽象的概念。它并不是真实存在的，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器的优化。本地内存中它存储了该线程以读或写共享变量拷贝的一个副本。
		`从更低的层次来说，主内存就是硬件的内存，是为了获取更高的运行速度，虚拟机及硬件系统可能会让工作内存优先存储于寄存器和高速缓存中，java内存模型中的线程的工作内存是CPU的寄存器和高速缓存的一个抽象的描述。而JVM的静态内存存储模型它只是对内存的一种物理划分而已。它只局限在内存，而且只局限在JVM的内存。
	*JMM中线程与主内存中同步的八种操作
		1.lock（锁定）：作用于主内存的变量，把一个变量标识变为一条线程独占状态
		2.unlock（解锁）：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定
		3.read（读取）：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用
		4.load（载入）：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中
		5.use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎
		6.assign（赋值）：作用于工作内存的变量，它把一个从执行引擎接受到的值赋值给工作内存的变量
		7.store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作
		8.write（写入）：作用于主内存的变量，它把store操作从工作内存中一个变量的值传送到主内存的变量中
	同步规则:
		``如果要把一个变量从主内存中赋值到工作内存，就需要按顺序得执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序得执行store和write操作，但java内存模型只要求上述操作必须按顺序执行，没有保证必须是连续执行
		``不允许read和load、store和write操作之一单独出现
		``不允许一个线程丢弃他的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中
		``不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步到主内存中
		``一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了load和assign操作
		``一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以同时被一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会解锁，lock和unlock必须成对出现
		``如果一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎中使用这个变量前需要重新执行load或assign操作初始化变量的值
		``如果一个变量事先没有被lock操作锁定，则不允许他执行unlock操作，也不允许去unlock一个被其他线程锁定的变量
		``对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）

	并发的优势与风险:
	  优势:
		速度：同时处理多个请求，响应更快；复杂的操作可以分成多个进程同时进行。
		设计：程序设计在某些情况下更简单，也可以有更多选择
		资源利用：CPU能够在等待IO的时候做一些其他的事情
	  风险:
	  	安全性：多个线程共享数据时可能会产生于期望不相符的结果
		活跃性：某个操作无法继续进行下去时，就会发生活跃性问题。比如死锁、饥饿问题
		性能：线程过多时会使得CPU频繁切换，调度时间增多；同步机制；消耗过多内存。

	并发模拟工具:
		PostMan
		Apache Bench(AB):
			ab -n 1000 -c 50 http://localhost:8080/test	 请求1000次,最多允许同时50次访问(并发数为50)
		JMeter
	并发模拟代码:
		Semaphore , CountDownLatch

	原子性:
		AtomicXXX: CAS(compareAndSwap), Unsafe.compareAndSwapInt
		底层实现:
		//var1,传过来的count对象(AtomicInteger)
		//var2,该对象工作内存中的值
		//var4,要增加的值
		public final int getAndAddInt(Object var1, long var2, int var4) {
		//获取底层的该对象的值,主内存中的值
	        int var5;
	        do {
	            var5 = this.getIntVolatile(var1, var2);
	            //不断获取底层的值,直到和当前对象(工作内存中的)值相等(var2=var5).CAS,最终的目的是返回对象最新的值
	        } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));
	        return var5;
	    }	

	    这里的compareAndSwapInt（var1, var2, var5, var5 + var4）换成 compareAndSwapInt（obj, offset, expect, update）能清楚一些，如果obj内的value和expect相等，就证明没有其他线程改变过这个变量，那么就更新它(主内存)为update,返回的值是var5给工作内存,然后工作内存又+1。

		CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。


		AtomicLong,LongAdder:(面试)
		AtomicLong:死循环方式,如果并发高竞争非常激烈，那么失败量就会很高，性能会受到影响
		LongAdder:jvm对long，double这些64位的变量拆成两个32位的操作,在高并发的场景，通过热点分区来提高并行度,缺点：在统计的时候如果有并发更新，可能会导致结果有些误差,要求数据精确的话不要使用

		compareAndSet:更多用到AtomicBoolean中,保证我们要控制的这段代码只被执行一次.

		AtomicReference:用法同AtomicInteger一样，但是可以放各种对象:AtomicReference<Integer> count = new AtomicReference<>(0);
		AtomicIntegerFieldUpdater:原子性的去更新某一个类的实例的指定的某一个字段.newUpdater()方法的第一个参数是某类的class文件,第二个参数是指定的字段名,注意:该字段必须是volatile修饰,并且不能是static修饰.

		AtomicStampReference:CAS的ABA问题
		ABA问题：在CAS操作的时候，其他线程将变量的值A改成了B由改成了A，本线程使用期望值A与当前变量进行比较的时候，发现A变量没有变，于是CAS就将A值进行了交换操作，这个时候实际上A值已经被其他线程改变过，这与设计思想是不符合的
		解决思路：每次变量更新的时候，把变量的版本号加一，这样只要变量被某一个线程修改过，该变量版本号就会发生递增操作，从而解决了ABA变化	

		AtomicLongArray可以指定更新一个数组指定索引位置的值compareAndSet(int i, long expect, long update)

		AtomicBoolean(平时用的比较多),在并发情况下可以让一段代码只被执行一次.
		AtomicBoolean isHappened =  new AtomicBoolean(false);
		if(isHappened.compareAndSet(false,ture)){
		//在高并发情况下if里面的代码只会被执行一次
			...
		}

	    native:
	    使用native关键字说明这个方法是原生函数，也就是这个方法是用C/C++语言实现的，并且被编译成了DLL，由java去调用。 这些函数的实现体在DLL中，JDK的源代码中并不包含，你应该是看不到的。对于不同的平台它们也是不同的。这也是java的底层机制，实际上java就是在不同的平台上调用不同的native方法实现对操作系统的访问的。

	    独占锁：是一种悲观锁，synchronized就是一种独占锁，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。

		乐观锁：每次不加锁，假设没有冲突去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁用到的机制就是CAS，Compare and Swap。CAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。

	原子性-锁-synchronize
	   synchronized：依赖JVM （主要依赖JVM实现锁，因此在这个关键字作用对象的作用范围内，都是同一时刻只能有一个线程进行操作的）
	   Lock：依赖特殊的CPU指令，代码实现，ReentrantLock

	   synchronize
	   修饰代码块:作用范围:大括号括起来的代码,作用于调用的对象.
	   修饰方法:作用范围:整个方法,作用于调用的对象.
	   修饰类:
	   synchronized (SyncronizedExample2.class){
	   ...
	   }
	   作用范围:括号括起来的部分,作用于该类的所有对象
	   修饰静态方法:作用范围:整个静态方法,作用于该类的所有对象

	   作用于调用的对象:多个线程同时执行同一个对象的example01.test()时,是一个先执行完再执行下一个.多个线程同时执行该类的两个对象example01.test(),example02.test(),结果是两个方法交替执行.
	   作用于调用的类:这个类的不同对象多线程执行方法,都是先执行完一个再执行下一个.
	原子性-对比
		synchronize:不可中断锁,适合竞争不激烈,可读性好
		lock:可中断锁,多样化同步,竞争激烈时能维持常态.
		Atomic:竞争激烈时能维持常态,比Lock性能好,但只能同步一个值

		“synchronized不能被继承”: synchronized并不属于方法定义的一部分，不能被继承。子类继承父类,子类覆写了该方法，如果在覆写时不明确写上synchronized，那这个方法就不是synchronized。换句话说，虽然继承了，但是没把synchronized继承下来.

		system.out.println在底层实现时本身会加上synchronized，会影响并发场景下的性能，也让本来的多线程并发变得多了很多阻塞，很多地方甚至变成单线程。因此，强烈建议别使用他

	线程安全性-可见性
		JVM对于可见性，提供了synchronized和volatile
		JMM关于synchronized的两条规定：
		线程解锁前，必须把共享变量的最新值刷新到主内存
		线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（注意：加锁与解锁是同一把锁）

		Volatile:通过加入内存屏障和禁止重排序优化来实现
		对volatile 变量写操作时，会在写操作后加入一条store屏障指令，将本地内存中的共享变量值刷新到主内存
		对volatile变量读操作时，会在读操作前加入一条load屏障指令，从主内存中读取共享变量
		volatitle的屏障操作都是CPU级别的,但不能保证原子性.其实它比较适合做状态标记量（不会涉及到多线程同时读写的操作）,而且要保证两点： 
		（1）对变量的写操作不依赖于当前值 
		（2）该变量没有包含在具有其他变量的不变的式子中 :
		程序的初始化标识:
		volatile boolean inited = false;
		//线程一：
		context = loadContext();
		inited = true;

		//线程二：
		while（!inited）{
		    sleep();
		}
		doSomethingWithConfig(context);

	线程安全性-有序性
		Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 
		java提供了 volatile、synchronized、Lock可以用来保证有序性 
        另外，java内存模型具备一些先天的有序性，即不需要任何手段就能得到保证的有序性。通常被我们成为happens-before原则（先行发生原则）。如果两个线程的执行顺序无法从happens-before原则推导出来，那么就不能保证它们的有序性，虚拟机就可以对它们进行重排序:

        程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作
		锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作
		volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作（重要）
		传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C
		线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作
		线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生
		线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行
		对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始


	安全发布对象-发布与逸出
		发布对象:使一个对象能够被当前范围之外的代码所使用。在我们的日常开发中，我们经常要发布一些对象，比如通过类的非私有方法返回对象的引用，或者通过公有静态变量发布对象。
	    对象逸出:一种错误的发布。当一个对象还没有构造完成时，就使它被其他线程所见。
	    不安全发布对象的两种代码演示:

	    如何安全发布对象？共有四种方法
	    1、在静态初始化函数中初始化一个对象引用
	    2、将对象的引用保存到volatile类型域或者AtomicReference对象中
	    3、将对象的引用保存到某个正确构造对象的final类型域中
	    4、将对象的引用保存到一个由锁保护的域中
	    我们用各种单例模式来演示其中的几种方法:懒汉式,饿汉式

	    静态块：用static申明，JVM加载类时执行，仅执行一次 
		构造块：类中直接用{}定义，每一次创建对象时执行 
		执行顺序优先级：静态块>main()>构造块>构造方法 
		静态块和静态属性优先执行，谁在前就先执行谁 

		单例: spring管理的bean通常都使用的单例，单例没有专属的使用场景，只要一个类实例化后可以一直使用，就可以设计成单例，减少频繁创建对象的开销

	不可变对象
		有一种对象只要它发布了就是安全的，它就是不可变对象。

		final关键字:
			修饰类：类不能被集成。
			  基础类型的包装类都是final类型的类。final类中的成员变量可以根据需要设置为final，但是要注意的是，final类中的所有成员方法都会被隐式的指定为final方法
			修饰方法：
			  (1)被继承后不能修改该方法
			  (2)效率：在早期的java实现版本中，会将final方法转为内嵌调用。但是如果方法过于庞大，可能看不见效果。一个private方法会被隐式的指定为final方法
			修饰变量：
			  基本数据类型变量，在初始化之后，它的值就不能被修改了。如果是引用类型变量，在它初始化之后便不能再指向另外的对象。(注意:被final修饰的引用类型变量，虽然不能重新指向，但是可以修改)

		创建不可变对象:
			1.Java的Collection类的unmodifiable相关方法,包含:unmodifiableList,unmodifiableMap,unmodifiableSet...
			   使用时: map = Collections.unmodifiableMap(map);

			   unmodifiable相关类的实现原理:
			   	 Collections.unmodifiableMap在执行时,将参数中的map对象进行了转换转换为Collection类中的内部类UnmodifiableMap对象。而UnmodifiableMap对map的更新方法（比如put、remove等）进行了重写，调用时均抛出UnsupportedOperationException异常，这样就做到了map对象的不可变。

			2.使用Guava的Immutable相关类,包含:ImmutableSet,ImmutableList,ImmutableMap...
				1)使用时: Immutablelist<Integer> list = ImmutableList.of(1,2,3);
					list.add(4);  这一句在书写完就会被IDE提示该add方法为过时方法，实际为不可用方法,运行时仍然会抛出UnsupportedOperationException异常.
				Immutable相关类实现原理:跟Java的unmodifiable相关类相似的实现方法.
				2)ImmutableSet除了使用of的方法进行初始化,还可以使用copyof方法,将Collection,iterator类型作为参数.
					private final static ImmutableSet set = ImmutableSet.copyOf(list);
					private final static ImmutableSet set = ImmutableSet.copyOf(list.iterator());
				3)ImmutableMap有特殊的builder写法：
					private final static ImmutableMap<Integer, Integer> map = ImmutableMap.of(1, 2, 3, 4);  //奇数位是key,偶数位是value
 					private final static ImmutableMap<Integer, Integer> map2 = ImmutableMap.<Integer, Integer>builder()
            		.put(1, 2).put(3, 4).put(5, 6).build();			//ImmutableMap的builder写法.

         问: ImmutableXXX修改的集合必须配上final才可以实现不可变对象，否则可以修改其对象引用，是这样吗?
         答: 是的，我们在使用一个不可变对象的实例时，其实很关键一点就是添加final修饰，否则我们很多接口来声明的类实例，在实际使用中被改了引用是一件很尴尬的事情。JDK里许多方法也要求传入接口参数必须是final修饰的变量，保证在方法处理过程中不会修改引用。否则一个参数传到一个方法将很不安全，因为你根本不知道这个方法会对传入的参数做怎样的处理，这也是一个比较好的实践，可以使用final时尽量使用。

    线程封闭:
        它其实就是把对象封装到一个线程里，只有一个线程能看到这个对象，那么这个对象就算不是线程安全的，也不会出现任何线程安全方面的问题。
        比如:
            JDBC的connection连接对象本身不是线程安全的,但是应用连接池,线程从连接池中取connection对象,在线程返回connection之前,连接池不会讲其分配给其他线程,等于将connection封闭到一个线程里面.这样虽然connection对象本身不是线程安全,但是同时连接池的线程封闭也能做到线程安全.
        (1)Ad-hoc 线程封闭：
        (2)堆栈封闭:
            堆栈封闭其实就是方法中定义局部变量。不存在并发问题。多个线程访问一个方法的时候，方法中的局部变量都会被拷贝一份到线程的栈中（Java内存模型），所以局部变量是不会被多个线程所共享的。
        (3)ThreadLocal 线程封闭: 特别好的线程封闭方法
            每个线程都会维护一个map,map的key是每个线程的名称而map的value就是我们要封闭的对象.多个线程互不干扰.

        ``创建一个包含ThreadLocal对象的类ThreadLocalCache，并提供基础的添加、删除、获取操作
        ``创建一个Filter,在Filter中对ThreadLocal做添加操作
        ``创建拦截器interceptor,重写preHandle()(它是进入url之前拦截处理)和afterCompletion()(它是执行完url之后拦截处理)方法,在afterCompletion方法中ThreadLocalCache.remove()释放,避免内存泄漏.
        ``在springboot的启动类Application中@Bean注册filter与interceptor.(也可以写一个配置类来@Bean注册)
        ``写一个Controller来模拟请求.
          先进filter,后进interceptor

        问:为什么要使用过滤器add和拦截器remove,用其中的一个就可以实现把
        答:首先如果项目里只有一个filter和一个interceptor，或者只有其中一种时，用其中一个就可以实现，这是没问题的。
           接下来，说一下这样做的目的。这样做，主要是考虑在项目中有多个filter和一个interceptor时，比如项目里同时有登录校验的filter、权限校验的filter，然后有一个interceptor做一些通用的记录（比如接口耗时）。这时，在登录校验的filter里把登录校验的信息写入threadLocal，然后需要在接口该执行的都执行完再从threadlocal中移除登录信息。在多个filter时，直接使用一个就很可能出现后面的filter还要使用，但是还没使用时就已经移除的情况。这时放到interceptor里保证最后阶段移除就明显更不容易出错了。

    常用的线程不安全的类:
    		(1)StringBuilder与StringBuffer
    			StringBuilder是线程不安全的，而StringBuffer是线程安全的。分析源码：StringBuffer的方法使用了synchronized关键字修饰。
    			StringBuilder效率高,可以在方法里做局部变量时使用,线程封闭.
    		(2)simpleDateFormat与jodatime插件
    			simpleDateFormat是线程不安全的,可以在new对象的时候将其放在方法里面,因为局部变量线程封闭,这样就是线程安全的.
    			jodatime插件可保证线程安全性.
    			Joda 类具有不可变性，因此它们的实例无法被修改。（不可变类的一个优点就是它们是线程安全的）
    			private static DateTimeFormatter dateTimeFormatter = DateTimeFormat.forPattern("yyyyMMdd");
    			private static void update(int i) {
    			    log.info("{}, {}", i, DateTime.parse("20180208", dateTimeFormatter).toDate());
    			}
    		(3)ArrayList,HashSet,HashMap等Collection类
    			线程不安全的原因,以arrayList为例,每次进行插入操作的时候,都会做扩容处理,会导致线程不安全.因为添加一个元素时会分两步来完成:
    				1.增大数组的size值
    				2.在数组Item[size]的位置存放此元素
    			由于这两步不是原子性的,所以多线程时会出现线程安全问题.
    		(4)先检查再执行: if(condition(a)){handle(a)};
    		   判断语句和执行语句无法保证原子性,所以线程不安全

    		问: 以下业务代码:
    		 for (Long houseId: houseIds) {
    		    //线程处理
    		    executorService.execute(() -> {
    		        //一些查询操作
    		        xxxService.select();
    		        //一些更新缓存的操作
    		        xxxRedis.update();
    		        if(如果不需要保存){
    				    //停止线程
    			        Thread.currentThread().interrup();
    		        }
    		        //一些添加操作
    		        xxxService.batchInsert();
    		    }
    		 }
    		 程序却会不断抛出InterruptedException,线程不是在wait, join, sleep时候被interrupt才会抛出这个异常吗?
    		答: 实际中很少有直接调用interrupt的，你如果想结束线程，直接return就可以了啊，你目前使用的是线程池，你很难知道其他线程是什么状态，完全交给线程池调度就可以了。

    		问: StringBuilder快，StringBuffer安全，那String这个类，顿时就有点尴尬了，那我们一般为什么不就用这两个类，干嘛还用String？（尽管我们知道，很多场景下，我们一般都是习惯性定义字符串为String）
    		这三者的应用场景有什么区别，什么情况下，我该用哪个类，尤其String类。
    		答: 字符串拼接的时候，用SringBuilder和StringBuffer性能更好，因为String是不能改变的，例如我们声明了一个String s = "abc";当我们改为String s = s+"de";的时候，其实是重新声明了一个String s，就是String s="abc"+"de";而不是直接在之前的String上面操作，所以会有性能上面的问题。而StringBuilder和StringBuffer调用append方法是直接在上面进行修改操作的，性能比String好。然后其余的问题就是StringBuilder是线程不安全的，而StringBuffer是线程安全的，在不同的场景进行选择了。 补充一点，如果String 后面是多个【常量】字符串拼接，其实和SringBuilder、StringBuffer也差不多，这时候编译器在编译阶段会做特殊的优化


    	同步容器:
    		(1)ArrayList的线程安全类: Vector和Stack
    		   Vector相当于加了synchronized的arrayList;
    		   Stack(栈)它继承了Vector,也是使用synchronized修饰了.
    		  但是同步容器在某些情况下是线程不安全的:
    		  比如并发执行删除与获取的操作.有可能上面刚删除完,下面就获取,就会报数组越界异常.因为synchronize只锁了方法,要想两个方法之间保证原子性就需要加上Lock或者synchronized来同步.
    		(2)HashMap的线程安全类: HashTable , 使用了synchronized修饰
            (3)Collections类中的相关同步方法:
                Collections.synchronizedList(List<T>);
                Collections.synchronizeMap(Map<K,T>);
                Collections.synchronizeSet(Set<T>);
                ...等等
             使用: private static List<Integer> list = Collections.synchronizedList(Lists.newArrayList());

             另外:使用foreach\iterator遍历集合的时候不能进行增删操作,会报错ConcurrentModificationException,使用for循环是ok的.
             解决办法:1.在循环里将循坏的对象标记,然后出循环时处理
                     2.在并发环境在可以通过加锁,或者使用并发容器来解决

        并发容器J.U.C:
            OOM - Out of Memory，内存溢出
            J.U.C是Java.util.concurrency缩写
            上面我们介绍了ArrayList、HashMap、HashSet对应的同步容器保证其线程安全，这节我们介绍一下其对应的并发容器。
            (1) ArrayList -> CopyOnWriteArrayList
                CopyOnWriteArrayList写操作时复制，当有新元素添加到集合中时，从原有的数组中拷贝一份出来，然后在新的数组上作写操作，将原来的数组指向新的数组。整个数组的add操作都是在锁的保护下进行的，防止并发时复制多份副本。读操作是在原数组中进行，不需要加锁
                ``缺点：
                1.写操作时复制消耗内存，如果元素比较多时候，容易导致young gc 和full gc。
                2.不能用于实时读的场景.由于复制和add操作等需要时间，故读取时可能读到旧值。
                能做到最终一致性，但无法满足实时性的要求，更适合读多写少的场景。
                ``优点:
                如果无法知道数组有多大，或者add,set操作有多少，慎用此类,在大量的复制副本的过程中很容易出错。
                设计思想：
                1.读写分离
                2.最终一致性
                3.使用时另外开辟空间，防止并发冲突
            (2) HashSet -> CopyOnWriteArraySet
                它是线程安全的，底层实现使用的是CopyOnWriteArrayList，因此它也适用于大小很小的set集合，只读操作远大于可变操作。因为他需要copy整个数组，所以包括add、remove、set它的开销相对于大一些。
            (3) TreeSet -> ConcurrentSkipListSet
                ``TreeSet: 它可以给Set集合中的元素进行指定方式(1自身具备比较性 2自定义比较器)的排序。
                ``同其他set集合，是基于map集合的（基于ConcurrentSkipListMap),在多线程环境下，里面的contains、add、remove操作都是线程安全的。
                ``多个线程可以安全的并发的执行插入、移除、和访问操作。但是对于批量操作addAll、removeAll、retainAll和containsAll并不能保证以原子方式执行，原因是addAll、removeAll、retainAll底层调用的还是contains、add、remove方法，只能保证每一次的执行是原子性的，代表在单一执行操纵时不会被打断，但是不能保证每一次批量操作都不会被打断。在使用批量操作时，还是需要手动加上同步操作的。
                ``不允许使用null元素的，它无法可靠的将参数及返回值与不存在的元素区分开来。
            (4) HashMap -> ConcurrentHashMap
                ``ConcurrentHashMap不允许空值,对读操作做了大量的优化,因此这个类在高并发环境下有特别好的表现,面试中经常问.
                ``ConcurrentHashMap作为Concurrent一族，其有着高效地并发操作，相比Hashtable的笨重，ConcurrentHashMap则更胜一筹了。
                ``在1.8版本以前，ConcurrentHashMap采用分段锁的概念，使锁更加细化，但是1.8已经改变了这种思路，而是利用CAS+Synchronized来保证并发更新的安全，当然底层采用数组+链表+红黑树的存储结构。
            (5) TreeMap -> ConcurrentSkipListMap
                ``底层实现采用SkipList跳表
                ``曾经有人用ConcurrentHashMap与ConcurrentSkipListMap做性能测试，在4个线程1.6W的数据条件下，前者的数据存取速度是后者的4倍左右。但是后者有几个前者不能比拟的优点：
                    1、Key是有序的
                    2、支持更高的并发，存储时间与线程数无关,也就是线程数越高越有优势

        安全共享对象策略:
            1.线程封闭: 一个被线程封闭的对象,由线程独占,并且只能被占有它的线程修改. 比如局部变量
            2.共享只读: 一个共享只读的对象, 可以被多个线程并发访问,但是任何线程都不能修改它. 比如不可变对象
            3.线程安全对象: 一个线程安全的对象或者容器,在内部通过同步机制来保障线程安全,其它线程无需额外的同步就可以通过公共接口随意访问它 , 比如并发容器(J.U.C)
            4.被守护对象: 被守护对象只能通过获取特定的锁来访问. 比如synchronize.lock加锁.

            问: 我看《Java并发编程实战》，里面介绍ReentrantReadWriteLock,读锁和写锁，里面说读锁类似于Semaphore而不是锁，只是维护当前活跃的读线程的数量，我知道读锁是共享锁而写锁是排它锁，那我的理解是共享锁不是一种真正的锁，那他又有什么意义呢？
            答: 你好，他存在的意义可以参考ReentrantLock，ReentrantLock实现了标准的互斥操作，也就是一次只能有一个线程持有锁，显然这个特点在一定程度上面减低了吞吐量。
            实际应用场景中我们会经常遇到这样的情况：某些资源需要并发访问，并且大部分时间是用来进行读操作的，写操作比较少，而锁是有一定的开销的，当并发比较大的时候，锁的开销就非常可观了。所以如果可能的话就尽量少用锁，如果非要用锁的话就尝试看能否能实现读写分离，将其改造为读写锁。
            ReentrantReadWriteLock主要就是为了解决这种场景，尽可能的减少排他锁的使用，同时也能保证足够的线程安全。
            问: 既然读操作很多，加排他锁的开销又大，那我直接对读操作不加任何锁不是更好吗，为啥还需要读锁
            答: 还记得课程开始部分讲线程安全时的例子不，不加锁时其他线程做了修改后，你当前的线程可能读取不到最新值，导致操作出现线程安全问题

            问: 老师，您好！volitile 修饰一个map 当map很大的时候会不会导致OOM？
            答: 你好，volatile本质上不会额外消耗内存，只是强制代码读取主存里最新的值。如果因为map过大导致oom，那本质上是map的问题，而不是因为有volatile修饰。
            问: 老师，主存是什么？我一直对这个词很模糊，是JVM里的堆，栈？
            答: 主存是公共空间，基本可以类比为虚拟机模型中的堆,对象创建好了都是在主存里，所有线程都可以访问。 工作内存是线程的私有内存，只有本线程可以访问，如果线程要操作主存中的某个对象，必须从主存中拷贝到工作内存，在对工作内存中的副本进行操作，操作后再写入主存，而不能对主存的对象直接操作。 volatile主要是在某些场合需要强制读取主存里的数据。

            问: 老师，copyonwriteArrayList的读没有加锁，为什么还是线程安全的呢？
                public E get(int index) {
                   return get(getArray(), index);
                }
               当一个线程copyonwriteArrayList调用add(int index, E element)时，另一个线程读的时候是原来的数组数据，不是脏读了吗？
            答: 你好,CopyOnWriteArrayList不适用于实时读的场景，像拷贝数组、新增元素都需要时间,所以调用一个set操作后,读取到数据可能还是旧的,虽然CopyOnWriteArrayList能做到最终一致性,但是还是没法满足实时性要求。因此如果对实时要求特别高，那么CopyOnWriteArrayList 可能确实不太适合，他主要用于读多写少的情景，这代表实际的写理论上会非常少，而且是通过最终数据的正确来保证线程安全。
            如果任何一个时间点都期望数据是正确的，那么这时候应该考虑使用同步容器，并发容器没法取代同步容器，并发容器更多的是在保证线程安全的大前提下，尽可能提升并发的性能


        J.U.C之AQS
            AQS全名：AbstractQueuedSynchronizer，是并发容器J.U.C（java.lang.concurrent）下locks包内的一个类。它实现了一个FIFO(FirstIn、FisrtOut先进先出)的队列。底层实现的数据结构是一个双向列表。
              Sync queue：同步队列，是一个双向列表。包括head节点和tail节点。head节点主要用作后续的调度。
              Condition queue：非必须，单向列表。当程序中存在cindition的时候才会存在此列表。
            AQS的大致实现思路:
              AQS内部维护了一个CLH队列来管理锁。线程会首先尝试获取锁，如果失败就将当前线程及等待状态等信息包装成一个node节点加入到同步队列sync queue里。
              接着会不断的循环尝试获取锁，条件是当前节点为head的直接后继才会尝试。如果失败就会阻塞自己直到自己被唤醒。而当持有锁的线程释放锁的时候，会唤醒队列中的后继线程。


        J.U.C之AQS--CountDownlatch

            CountDownLatch，通过给定的计数器数值为其初始化，该计数器是原子性操作，保证同时只有一个线程去操作该计数器。调用该类await方法的线程会一直处于阻塞状态。只有其他线程调用countDown方法（每次使计数器-1）,使计数器归零(即其他方法都执行完)才能继续执行。
                CountDownLatch countDownLatch = new CountDownLatch(200);
                countDownLatch.countDown();
                countDownLatch.await();
            CountDownLatch的await方法还有重载形式，可以设置等待的时间，主线程到这里先阻塞,如果超过此时间，则主线程不继续等待,往下执行(用在某些复杂的功能:要给定执行时间,超过这个时间就算没执行完主线程也要接着往下执行的情况,但是之前的其他多线程也会执行完)：
                countDownLatch.await(10, TimeUnit.MILLISECONDS);

            问: countDownLatch 的作用在哪里呢，保证线程安全吗?
            答: 你好，countDownLatch不是用来做线程安全的，他是一个做线程同步的组件。本质上是可以让主线程在当前阻塞，等待其他线程执行完（通过countDown方法）再继续执行。
            课程里计数的例子添加了countDownLatch的作用：主线程开启了很多线程去运算，希望在所有线程执行完再去打印结果，而countDownLatch就能保证主线程一直阻塞在那里，直到那些线程都执行完。而如果不加这个控制，直接放入线程池就打印，那样可能任务还没调度完，就已经输出count值了，这时候count如果有错，是无法判断是线程不安全导致的，还是线程没都执行完导致的。
            继续说一下实际中我们会在什么场景使用countDownLatch：比如现在有一个任务，需要开启多个线程去处理，然后在任务执行完去做后面的事情。这时候，要保证开启多个线程都处理完再继续后面的操作，就需要借助countDownLatch了。


        J.U.C之AQS--Semaphore

            保证同一时刻并发访问的线程数目,用于仅能提供有限个数的访问资源,比如数据库的有效连接个数.
            final Semaphore semaphore = new Semaphore(3);
            semaphore.acquire();
            test();
            semaphore.release();

            如果并发特别多,需要丢弃一部分许可:
            1.semaphore.tryAcquire()尝试获取一个许可.未得到许可的丢弃.
            2.semaphore.tryAcquire(5000, TimeUnit.MILLISECONDS)  尝试获取许可一段时间，未得到许可的线程丢失

            注意: 测试代码不用@test，改成用main主方法，JUnit在进行单元测试的时候，如果被@Test注释的方法执行完成，那么内部开启的线程也会被强制退出，退出是测试框架进行的操作。

            问: 老师，Semaphore和RateLimiter根据他们的特性，都是可以用来限制并发，那么这两者有什么区别呢？
            答: 你好，Semaphore：信号量，直译很难理解。作用是限定只有抢到信号的线程才能执行，其他的都得等待！你可以设置N个信号，这样最多可以有N个线程同时执行。注意，其他的线程也在，只是挂起了.RateLimiter是guava的，直译是速率限制器。其作用是 限制一秒内只能有N个线程执行，超过了就只能等待下一秒。注意，N是double类型。前者控制的是同一时刻同时运行的线程数目，后者控制的是1s内允许执行的次数，效果上是不同的。
            问: 那假设要执行10万次数据库插入操作，使用RateLimiter进行限制，每秒运行执行300次，那么10万次操作在一秒内并发执行的的时候，剩余的99700次操作是不是会被丢弃？
            答: 可以控制丢弃或者慢慢处理.
            问: 如果有的话应该也是通过acquire或者tryAcquire来区别的吧，我看到Semaphore和RateLimiter都有这两个方法。那么，老师，如果要在某个数据库方法内限制执行次数，是不是使用RateLimiter更合理？
            答: 嗯，是的，控制1s内处理的个数，使用信号量的话，可能处理的特别快，导致短时间内入库太多数据，直接出现主从延迟变大等情况。


        J.U.C之AQS--CyclicBarrier:

        	多线程计算数据,最后合并计算结果的.

        	catchDownLatch:一个或者n个线程等待其他线程执行完才能继续执行. 计数器只能用一次.
        	CyclicBarrier:多个线程相互等待,直到所有的线程满足条件以后才继续执行.每当有一个线程执行了await方法，计数器就会执行+1操作，待计数器达到预定的值，所有的线程再同时继续执行。由于计数器释放之后可以重用（reset方法），所以称之为循环屏障。计数器可以重复使用.

        	barrier.await(2000,TimeUnit.MILLISECONDS); 会抛出异常,需要try-catch捕获,如果不捕获的话会影响下面的程序执行
        	try{
        		barrier.await(2000, TimeUnit.MILLISECONDS);
        	} catch (Exception e) {
        		log.warn("BarrierException" ,e)
        	}
        	log.info("{} continue" , threadNum);
        	CycliBarrier barrier = new CyclicBarrier(5 , () -> {
        		log.info("callback is running");
        	}) 进入屏障后(满足有5个线程await),优先执行runnable.


       	J.U.C之AQS--ReentrantLock
       	  java中有两类锁，一类是Synchronized，而另一类就是J.U.C中提供的锁。ReentrantLock与Synchronized都是可重入锁，本质上都是lock与unlock的操作。接下来我们介绍三种J.U.C中的锁，其中 ReentrantLock使用synchronized与之比对介绍。

       	  ReentrantLock与synchronized的区别:
       	  	``可重入性：两者的锁都是可重入的，差别不大，有线程进入锁，计数器自增1，等下降为0时才可以释放锁
		    ``锁的实现：synchronized是基于JVM实现的（用户很难见到，无法了解其实现），ReentrantLock是JDK实现的。
			``性能区别：在最初的时候，二者的性能差别差很多，当synchronized引入了偏向锁、轻量级锁（自选锁）后，二者的性能差别不大，官方推荐synchronized（写法更容易、在优化时其实是借用了ReentrantLock的CAS技术，试图在用户态就把问题解决，避免进入内核态造成线程阻塞）
			``功能区别：
			（1）便利性：synchronized更便利，它是由编译器保证加锁与释放。ReentrantLock是需要手动释放锁，所以为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。
			（2）锁的细粒度和灵活度，ReentrantLock优于synchronized

		  ReentrantLock独有的功能:
		  	``可以指定是公平锁还是非公平锁(在new对象时可以指定),sync只能是非公平锁.（所谓公平锁就是先等待的线程先获得锁）
			``提供了一个Condition类，可以分组唤醒需要唤醒的线程.不像是synchronized要么随机唤醒一个线程，要么全部唤醒。
			``提供能够中断等待锁的线程的机制，通过lock.lockInterruptibly()实现，这种机制ReentrantLock是一种自选锁，通过循环调用CAS操作来实现加锁。性能比较好的原因是避免了进入内核态的阻塞状态。

		  Condition的使用:
		  	Condition可以非常灵活的操作线程的唤醒，下面是一个线程等待与唤醒的例子，其中用1234序号标出了日志输出顺序:
		  	public static void main(String[] args) {
		  	ReentrantLock reentrantLock = new ReentrantLock();
		  	Condition condition = reentrantLock.newCondition();//创建condition
		  	//线程1
		  	new Thread(() -> {
		        try {
			            reentrantLock.lock();
			            log.info("wait signal"); // 1
			            condition.await();
			        } catch (InterruptedException e) {
			            e.printStackTrace();
			        }
			        log.info("get signal"); // 4
			        reentrantLock.unlock();
			    }).start();
			//线程2
		    new Thread(() -> {
		        reentrantLock.lock();
		        log.info("get lock"); // 2
		        try {
		            Thread.sleep(3000);
		        } catch (InterruptedException e) {
		            e.printStackTrace();
		        }
		        condition.signalAll();//发送信号
		        log.info("send signal"); // 3
		        reentrantLock.unlock();
		   		}).start();
			}

			输出过程讲解：
			1、线程1调用了reentrantLock.lock()，线程进入AQS等待队列，输出1号log
			2、接着调用了awiat方法，线程从AQS队列中移除，锁释放，直接加入condition的等待队列中
			3、线程2因为线程1释放了锁，拿到了锁，输出2号log
			4、线程2执行condition.signalAll()发送信号，输出3号log
			5、condition队列中线程1的节点接收到信号，从condition队列中拿出来放入到了AQS的等待队列,这时线程1并没有被唤醒。
			6、线程2调用unlock释放锁，因为AQS队列中只有线程1，因此AQS释放锁按照从头到尾的顺序，唤醒线程1
			7、线程1继续执行，输出4号log，并进行unlock操作。

       	  读写锁：ReentrantReadWriteLock读写锁
       		在没有任何读写锁的时候才能实现写入操作,悲观读取,在获取写入锁的时候,不允许有任何读锁还保持.如果读多写少的话会导致写锁饥饿,因为读锁一直被使用,写锁无法执行.
       		 private final Lock readLock = lock.readLock();//读锁
    		 private final Lock writeLock = lock.writeLock();//写锁

       	  票据锁：StempedLock
       	  	它控制锁有三种模式（写、读、乐观读）。一个StempedLock的状态是由版本和模式两个部分组成。锁获取方法返回一个数字作为票据（stamp），他用相应的锁状态表示并控制相关的访问。数字0表示没有写锁被锁写访问，在读锁上分为悲观锁和乐观锁。
       	  	乐观读：如果读的操作很多写的很少，我们可以乐观的认为读的操作与写的操作同时发生的情况很少，因此不悲观的使用完全的读取锁定。程序可以查看读取资料之后是否遭到写入资料的变更，再采取之后的措施。

       	  synchronized锁:在JVM层面实现锁定,JVM会替我们释放锁定.
       	  ReentrantLock,ReentrantReadWriteLock,StampedLock: 是对象层面的锁定,要保证锁一定会被释放就需要将解锁其放在finally里面,不然会死锁.
       	  StampedLock对吞吐量有巨大的改进,特别是在读线程越来越多的场景下.

       	  如何选择锁?:
       	  1、当只有少量竞争者，使用synchronized
		  2、竞争者不少但是线程增长的趋势是能预估的，使用ReetrantLock
		  3、synchronized不会造成死锁，jvm会自动释放死锁。

		  问: 老师，为什么加锁释放锁本身可以是安全的？另外，假若面试时，被问到锁机制的底层是怎么实现的，我该怎么说比较好，毕竟锁的类别也很多。。
		  答: 你这里说的锁应该都是针对ReentrantLock这种独享锁，他的安全主要提现在一旦加锁，就只有一个线程可以通过，相当于单线程操作，因此可以保证安全。
		  对于面试中问到，可以这样去回答：课程里介绍了三类锁，核心代表是 synchronized、AtomicXXX、ReentrantLock
		  synchronized属于java提供的关键字，他的实现是借助于cpu指令的字节码来实现的。
		  AtomicXXX本质上其实不是锁，而是通过CAS自旋（循环尝试去更新，直至成功)与volatile变量互相配合来保证线程安全的更新
		  ReentrantLock则是基于AQS进行的实现，核心是借助里面CLH队列实现锁的排队策略

		  问: 多线程的代码是如何调试的?
		  答: 我们调试只能看单线程的内容，会影响多线程的执行.
		  实际开发中，我们做多线程处理时，对输出的log讲究很多,核心环节必须输出log及相关变量值。一个配置好的log在做输出时，通常会包含时间及线程名，真出问题时，需要找到相关的日志，然后分析线程的运行情况，确定问题根本原因。
		  这也说明，log的记录很重要。

		  面试题: 对象锁和类锁的区别?
		  答: 对象锁锁的是这个类的某一个对象,类锁锁的是这个类的所有对象
		  作用于调用的对象:多个线程同时执行同一个对象的example01.test()时,是一个先执行完再执行下一个.多个线程同时执行该类的两个对象example01.test(),example02.test(),结果是两个方法交替执行.
	   	  作用于调用的类:这个类的不同对象多线程执行方法,都是先执行完一个再执行下一个.

		  注意: 不要使用system.out的打印结果来验证多线程的输出结果，请使用课程里介绍的log或者自己定义一个log。你这样输出的结果是无法具体确认是哪个线程执行的，尤其是你要分析的内容与哪个线程执行有关，而log在输出日志则会带上时间和实际执行的线程，这两项对结果的分析至关重要。


    J.U.C--FutureTask

		  FutureTask是J.U.C中的类，是一个可删除的异步计算类。这个类提供了Future接口的的基本实现，使用相关方法启动和取消计算，查询计算是否完成，并检索计算结果。只有在计算完成时才能使用get方法检索结果;如果计算尚未完成，get方法将会阻塞。一旦计算完成，计算就不能重新启动或取消(除非使用runAndReset方法调用计算)。

		  new Thread()和Runnable()的缺点:线程执行完之后无法获取返回值,Java1.5之后就提供了Callable与Future，这两个接口就可以实现获取任务执行结果

		  Future接口:FutrueExample
		  FutureTask实现了RunnableFuture接口，而RunnableFuture接口继承了Runnable与Future接口，所以它既可以作为Runnable被线程中执行，又可以作为callable获得返回值。

		  问: 同样的代码，为什么我的代码先执行的do something in main， 后执行的do something in callable呢？这个和线程优先级有关系吗？
          答: 当前线程额外启动了一个线程，这时当前线程和额外启动的线程由于受CPU调度的影响，执行先后并不是完全确定的，你如果多执行几次，应该也会出现我课程演示时相同的结果。不过有一点可以肯定的是，发生这种情况时，大家执行的时间都会非常的接近，应该是毫秒级别相差无几。这个例子也说明了一个问题，就是两个线程定义的先后顺序决定不了执行的顺序。


	J.U.C--Fork/Join框架

        ForkJoin是Java7提供的一个并行执行任务的框架，是把大任务分割成若干个小任务，待小任务完成后将结果汇总成大任务结果的框架。主要采用的是工作窃取算法，工作窃取算法是指某个线程从其他队列里窃取任务来执行。
        在窃取过程中两个线程会访问同一个队列，为了减少窃取任务线程和被窃取任务线程之间的竞争，通常我们会使用双端队列来实现工作窃取算法。被窃取任务的线程永远从队列的头部拿取任务，窃取任务的线程从队列尾部拿取任务。

        局限性:
        1、任务只能使用fork和join作为同步机制，如果使用了其他同步机制，当他们在同步操作时，工作线程就不能执行其他任务了。比如在fork框架使任务进入了睡眠，那么在睡眠期间内在执行这个任务的线程将不会执行其他任务了。
        2、我们所拆分的任务不应该去执行IO操作，如读和写数据文件。
        3、任务不能抛出检查异常。必须通过必要的代码来处理他们。

        框架核心:
        核心有两个类：ForkJoinPool | ForkJoinTask
        ForkJoinPool：负责来做实现，包括工作窃取算法、管理工作线程和提供关于任务的状态以及他们的执行信息。
        ForkJoinTask:提供在任务中执行fork和join的机制。


        问: mapreduce与fork join区别 ？查了一些相关资料但是还是比较懵逼  比较不出优略。或者说各自的优势
        答: map reduce与fork join区别 。他俩最大的区别是，fork join主要是在一个jvm上进行使用的，而map reduce是明确设计为在集群上工作。同时呢,forkjoin是将任务分割成多个子任务的，以递归的方式，可以有很多层，更充分地利用内核；map reduce 则是做一个大的分裂，单层，分裂之后互相之间没有通信，并可大规模扩展.

        问: fork join 与 与多线程操作然后等待主线程统一返回有什么区别?
        答: fork join主要是不断拆分自己的任务，主要是为了完成同一个任务。而主线程等待子线程可以是不同的任务，只是在保证都结束后再继续后面的操作。在计算单一任务时，fork join会更有优势。

        问: Semaphore与newCachedThreadPool联合使用与 newFixedThreadPool的区别,Semaphore与newCachedThreadPool联合使用的目的是为了防止无限的消耗内存？但是直接用newFixedThreadPool或者说直接手动写一个线程池，定义一个有界队列哪怕把队列值写的很大也是可以的啊?
        答: 线程池控制的是线程数量，而信号量控制的是并发数量，虽然说这个看起来一样，但是还是有区别的.信号量的调用，当达到数量后，线程还是存在的，只是被挂起了而已。而线程池，同时执行的线程数量是固定的，超过了数量的只能等待。

        问: 老师 , 我在学习ForkJoin的时候看到了廖雪峰老师的一篇文章 , 不知道老师有没有看过这篇文章 , 链接在这里 https://www.liaoxuefeng.com/article/001493522711597674607c7f4f346628a76145477e2ff82000  他在文章中提到 我们在课程中的实例不妥 ,他认为我们的这种写法不符合Fork/Join模型的任务执行逻辑, 老师怎么看 ,还是说我对两位老师的代码示例理解有误 ,他在文章中使用的 invoke 提交 task 的 , 我搜索了一下别人对invoke和submit 的解释,感觉都不是很明白,我想问问invoke和submit有什么区别 ,什么情况下适合使用submit , 什么情况下适合使用invoke ?
        答: 你好，先说第一个问题，使用fork方法不是最高效的，这个确实如此，关于这个问题，网上很多文章也在说，比如：https://blog.csdn.net/cxl0921/article/details/76460909  ，https://www.cnblogs.com/Redvelvet/p/4918307.html。那么，既然fork不是最高效的，为什么还要用他来举例子呢，就ForkJoin而言，直接使用fork、join两个方法来举例子大家更容易理解也更容易记住他。提到ForkJoin，你可能直接就会想起这两个方法以及能解决的问题。随着学习的深入，invokeAll就出现了，相比fork，他可以更好的利用线程池，实际表现也更好。因为ForkJoin大家平时用的并不多，因此课程在ForkJoin这里没打算讲太多的细节，不过，课程里如果直接给出invokeAll的对比，效果应该会更好些。
        再来说一下这里submit和invoke的区别。invoke是同步执行，调用之后需要等待任务完成，才能执行后面的代码；submit是异步执行，只有在Future调用get的时候会阻塞。

